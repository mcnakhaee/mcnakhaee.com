[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Muhammad Chenariyan Nakhaee",
    "section": "",
    "text": "I’m originally from Iran but I live and work in the Netherlands since 2018. I’ve had different roles in the world of data including researcher, data scientist, and data engineer. But I’m currently an AI Engineer working for a Dutch company. I mostly use Python for my day-to-day job but my true passion is creating data visualizations and R. Also known as: Muhammad Nakhaee, Muhammad C. Nakhaee\n\n\n\n\nIn the past few years, I have realized that I enjoy exploring my creative side and making different things. My true passion is creating charts and graphs (which is why I started this blog). I also enjoy photography and have a collection of old cameras that I use for my photography.\nI have worked on various projects in the data world, from machine learning, AI, and data engineering to data visualization. In my current job, I am an AI engineer working on our RAG solutions and developing agents.\n\n\n\nTechnologies:\n\nPython\nR\nDatabases & APIs\nCloud Technolgies most notably Azure and AWS\n\n\n\n\nI enjoy creating data visualization\nSkills: - Data analysis - GenAI and LLMs - Machine learning - Data Visualization - Statistical modeling - A little bit of data engineering\n\n\n\nRecently I gave a talk at Pydata about how I use AI for creating data visualizations\n\n\n\n\n\n\nWhen I’m not coding or analyzing data, you can find me:\n\n Reading about technology and science\n Photography and collecting old cameras\n Screenprinting and doing different art projects\n Fencing\n Hiking and exploring nature\n\n\n\n\nI’m always interested in connecting with fellow developers, data enthusiasts, and interesting people. Feel free to reach out!\n\n\n\n\n\n\nNoteContact Information\n\n\n\n\n GitHub: github.com/mcnakhaee\n Twitter: @m_cnakhaee\n LinkedIn: linkedin.com/in/muhammadcnakhaee\n Instagram: @mcnakhaee\n\n\n\n\n\n\n\n\nThis website is built using Quarto but previously, I used the {distill} package and Hugo with the blogdown package.\n\n\n\n\n\n\nTipLet’s Connect!\n\n\n\nI’m always interested in connecting with fellow data scientists, developers, and researchers. Feel free to reach out through any of my social channels!"
  },
  {
    "objectID": "about.html#hello-im-muhammad-chenariyan-nakhaee",
    "href": "about.html#hello-im-muhammad-chenariyan-nakhaee",
    "title": "About Muhammad Chenariyan Nakhaee",
    "section": "",
    "text": "I’m originally from Iran but I live and work in the Netherlands since 2018. I’ve had different roles in the world of data including researcher, data scientist, and data engineer. But I’m currently an AI Engineer working for a Dutch company. I mostly use Python for my day-to-day job but my true passion is creating data visualizations and R. Also known as: Muhammad Nakhaee, Muhammad C. Nakhaee"
  },
  {
    "objectID": "about.html#what-i-do",
    "href": "about.html#what-i-do",
    "title": "About Muhammad Chenariyan Nakhaee",
    "section": "",
    "text": "In the past few years, I have realized that I enjoy exploring my creative side and making different things. My true passion is creating charts and graphs (which is why I started this blog). I also enjoy photography and have a collection of old cameras that I use for my photography.\nI have worked on various projects in the data world, from machine learning, AI, and data engineering to data visualization. In my current job, I am an AI engineer working on our RAG solutions and developing agents.\n\n\n\nTechnologies:\n\nPython\nR\nDatabases & APIs\nCloud Technolgies most notably Azure and AWS\n\n\n\n\nI enjoy creating data visualization\nSkills: - Data analysis - GenAI and LLMs - Machine learning - Data Visualization - Statistical modeling - A little bit of data engineering\n\n\n\nRecently I gave a talk at Pydata about how I use AI for creating data visualizations"
  },
  {
    "objectID": "about.html#interests-hobbies",
    "href": "about.html#interests-hobbies",
    "title": "About Muhammad Chenariyan Nakhaee",
    "section": "",
    "text": "When I’m not coding or analyzing data, you can find me:\n\n Reading about technology and science\n Photography and collecting old cameras\n Screenprinting and doing different art projects\n Fencing\n Hiking and exploring nature"
  },
  {
    "objectID": "about.html#get-in-touch",
    "href": "about.html#get-in-touch",
    "title": "About Muhammad Chenariyan Nakhaee",
    "section": "",
    "text": "I’m always interested in connecting with fellow developers, data enthusiasts, and interesting people. Feel free to reach out!\n\n\n\n\n\n\nNoteContact Information\n\n\n\n\n GitHub: github.com/mcnakhaee\n Twitter: @m_cnakhaee\n LinkedIn: linkedin.com/in/muhammadcnakhaee\n Instagram: @mcnakhaee"
  },
  {
    "objectID": "about.html#about-this-site",
    "href": "about.html#about-this-site",
    "title": "About Muhammad Chenariyan Nakhaee",
    "section": "",
    "text": "This website is built using Quarto but previously, I used the {distill} package and Hugo with the blogdown package.\n\n\n\n\n\n\nTipLet’s Connect!\n\n\n\nI’m always interested in connecting with fellow data scientists, developers, and researchers. Feel free to reach out through any of my social channels!"
  },
  {
    "objectID": "workingposts/cineville-wrapped/cineville-wrapped/index.html",
    "href": "workingposts/cineville-wrapped/cineville-wrapped/index.html",
    "title": "Cineville Wrapped 2025",
    "section": "",
    "text": "Cineville Wrapped is a personal data visualization project that summarizes my movie-watching journey in 2025 using my Cineville pass. Inspired by Spotify Wrapped, this interactive scrollytelling experience takes viewers through various aspects of my cinema habits throughout the year."
  },
  {
    "objectID": "workingposts/cineville-wrapped/cineville-wrapped/index.html#overview",
    "href": "workingposts/cineville-wrapped/cineville-wrapped/index.html#overview",
    "title": "Cineville Wrapped 2025",
    "section": "",
    "text": "Cineville Wrapped is a personal data visualization project that summarizes my movie-watching journey in 2025 using my Cineville pass. Inspired by Spotify Wrapped, this interactive scrollytelling experience takes viewers through various aspects of my cinema habits throughout the year."
  },
  {
    "objectID": "workingposts/cineville-wrapped/cineville-wrapped/index.html#key-features",
    "href": "workingposts/cineville-wrapped/cineville-wrapped/index.html#key-features",
    "title": "Cineville Wrapped 2025",
    "section": "Key Features",
    "text": "Key Features\n\n\nVisual Statistics\n\nTotal screenings and hours watched\nNumber of cinemas and cities visited\nAverage rating and rated films count\n\n\n\nInteractive Visualizations\n\nGenre treemap breakdown\nLanguage distribution bars\nKeyword cloud visualization\n\n\n\n\n\nCinema Map\n\nInteractive MapLibre GL map\nAll cinemas visited with visit counts\nPopup information on hover\n\n\n\nRating Analysis\n\nBeeswarm plot with movie posters\nTop rated and least rated films\nGuilty pleasures and hot takes"
  },
  {
    "objectID": "workingposts/cineville-wrapped/cineville-wrapped/index.html#technology-stack",
    "href": "workingposts/cineville-wrapped/cineville-wrapped/index.html#technology-stack",
    "title": "Cineville Wrapped 2025",
    "section": "Technology Stack",
    "text": "Technology Stack\n\nFrontend\n\nD3.js v7 - Data-driven document manipulation\nScrollama - Scroll-driven storytelling library\nMapLibre GL - Interactive vector maps\nTailwind CSS - Utility-first CSS framework\n\n\n\nVisualizations\n\nTreemap - Genre breakdown\nBubble/Pack Layout - Keyword cloud\nBeeswarm Plot - Rating distribution with movie posters\nHeatmap - Cinema activity calendar\nBar Charts - Top cinemas and languages\n\n\n\nData Processing\n\nPython - Data enrichment and geocoding\nTMDB API - Movie metadata (posters, ratings, genres)"
  },
  {
    "objectID": "workingposts/cineville-wrapped/cineville-wrapped/index.html#how-it-works",
    "href": "workingposts/cineville-wrapped/cineville-wrapped/index.html#how-it-works",
    "title": "Cineville Wrapped 2025",
    "section": "How It Works",
    "text": "How It Works\n\nData Collection: Export Cineville viewing history\nEnrichment: Match with TMDB for posters, genres, and ratings\nGeocoding: Add coordinates for cinema locations\nVisualization: D3.js renders interactive charts in film-strip frames\nScrollytelling: Scrollama triggers frame transitions as user scrolls"
  },
  {
    "objectID": "workingposts/cineville-wrapped/cineville-wrapped/index.html#design-approach",
    "href": "workingposts/cineville-wrapped/cineville-wrapped/index.html#design-approach",
    "title": "Cineville Wrapped 2025",
    "section": "Design Approach",
    "text": "Design Approach\nThe design mimics a classic film strip aesthetic with:\n\nSprocket holes on top and bottom of each frame\nSliding transitions between frames\nWarm, cinema-inspired color palette (#F8EBD8 background)\nFilm-strip frame counter\nResponsive design for mobile viewing"
  },
  {
    "objectID": "workingposts/cineville-wrapped/cineville-wrapped/index.html#project-links",
    "href": "workingposts/cineville-wrapped/cineville-wrapped/index.html#project-links",
    "title": "Cineville Wrapped 2025",
    "section": "Project Links",
    "text": "Project Links\n\n\n\n\n\n\nTipView the Project\n\n\n\n\nLive Demo: View Cineville Wrapped\nBlog Post: Read the Blog Post"
  },
  {
    "objectID": "workingposts/cineville-wrapped/cineville-wrapped/index.html#challenges-solved",
    "href": "workingposts/cineville-wrapped/cineville-wrapped/index.html#challenges-solved",
    "title": "Cineville Wrapped 2025",
    "section": "Challenges Solved",
    "text": "Challenges Solved\n\nResponsive Film Strip: Adapting the film strip aesthetic for all screen sizes\nScroll Performance: Optimizing D3 transitions during scroll events\nMap Integration: Combining MapLibre GL with D3 visualizations\nPoster Beeswarm: Creating a force-simulation beeswarm with movie poster images"
  },
  {
    "objectID": "workingposts/cineville-wrapped/cineville-wrapped/index.html#what-i-learned",
    "href": "workingposts/cineville-wrapped/cineville-wrapped/index.html#what-i-learned",
    "title": "Cineville Wrapped 2025",
    "section": "What I Learned",
    "text": "What I Learned\nBuilding this project taught me:\n\nScrollama Integration: Creating smooth scroll-triggered animations\nD3.js Layouts: Working with treemap, pack, and force layouts\nMapLibre GL: Adding custom markers and popups\nResponsive SVG: Making D3 visualizations mobile-friendly\nFilm Strip CSS: Creating realistic film strip effects with CSS\n\n\nStatus: Complete - January 2025"
  },
  {
    "objectID": "workingposts/how-I-won-a-kaggle-prize-with-ggplot2/index.html",
    "href": "workingposts/how-I-won-a-kaggle-prize-with-ggplot2/index.html",
    "title": "How I won a Kaggle Prize with ggplot2",
    "section": "",
    "text": "This is the story of how I won a Kaggle prize in a competition 3 years ago using ggplot2. I’m writing about this story for the first because I think I want to share it how data visualization and ggplot2 helped me tremendously in my storytelling\n3 years ago I particiapted in the Kaggle Survey 2022 ( which unfortunetly became the last edition of this comptettion)\nSince I was a kid I was into fantasy books although due my increasing age I cannot say it’s true anymore. So, I thought what if the data science roles would be a a role in a fantasy world like the world of the Lord of the Rings where different people with differnt backgrounds and skills went on the same mission. But I still needed to incorporate that into my analysis so my visualizations convey the fantasy narrative that I had in mind.\nThen I also took\nsss"
  },
  {
    "objectID": "claudemdfiles/SEO_SETUP_GUIDE.html",
    "href": "claudemdfiles/SEO_SETUP_GUIDE.html",
    "title": "Google Search Engine Optimization (SEO) Setup Guide",
    "section": "",
    "text": "Your Quarto website is now configured for better search engine indexing:\n\n\n\nQuarto automatically generates sitemap.xml at https://mcnakhaee.com/sitemap.xml\nThis helps Google discover all your pages\n\n\n\n\n\nCreated robots.txt file that tells search engines they can crawl your site\nPoints to your sitemap\n\n\n\n\n\nAdded description, keywords, and Open Graph tags\nEnabled Twitter Card support\nAdded structured metadata to homepage\n\n\n\n\n\nBlog RSS feed available at https://mcnakhaee.com/blog/index.xml\n\n\n\n\n\n\n\n\nGo to Google Search Console\nClick “Start Now” and sign in with your Google account\nClick “Add Property”\nEnter your domain: mcnakhaee.com\n\n\n\n\nChoose one of these verification methods:\n\n\n\nGoogle will give you an HTML file to download (e.g., google1234567890abcdef.html)\nPlace this file in the root of your website directory\nRender your site: quarto render\nCommit and push to GitHub\nWait for Netlify to deploy\nClick “Verify” in Google Search Console\n\n\n\n\n\nGoogle will give you a meta tag like: &lt;meta name=\"google-site-verification\" content=\"abc123...\" /&gt;\nAdd this to your index.qmd frontmatter:\n---\ntitle: \"Muhammad Nakhaee\"\ngoogle-site-verification: \"abc123...\"\n---\nRender, commit, push, and verify\n\n\n\n\n\n\nOnce verified, in Google Search Console, go to “Sitemaps”\nEnter: sitemap.xml\nClick “Submit”\n\n\n\n\n\nGo to Google Analytics\nCreate a new property for your website\nGet your Measurement ID (format: G-XXXXXXXXXX)\nUpdate _quarto.yml with your real ID:\ngoogle-analytics: \"G-YOUR-ACTUAL-ID\"\nRender, commit, and push\n\n\n\n\n\n\n\n\nDescriptive page titles\nMeta descriptions\nSemantic HTML structure\nMobile-responsive design\nFast loading (static site)\nHTTPS (via Netlify)\nSocial media meta tags\n\n\n\n\n\nAdd alt text to all images - Helps with accessibility and SEO\nInternal linking - Link between related posts and pages\nRegular content updates - Post consistently to your blog\nQuality content - Focus on valuable, original content\nShare on social media - Increases visibility and backlinks\n\n\n\n\n\nAfter submitting to Google Search Console: - Wait 24-48 hours for Google to crawl your site - Check coverage report in Search Console - Use site search: site:mcnakhaee.com in Google to see indexed pages\n\n\n\nGoogle Search Console provides: - Number of indexed pages - Search queries bringing traffic - Click-through rates - Mobile usability issues - Security problems\n\n\n\n# Render your site locally\nquarto render\n\n# Add files and commit\ngit add .\ngit commit -m \"Update SEO configuration\"\n\n# Push to deploy\ngit push origin quarto\n\n\n\n\nGoogle Search Console Help\nQuarto SEO Documentation\nNetlify SEO Guide\n\n\nNote: Google indexing can take several days to weeks. Be patient and keep creating quality content!"
  },
  {
    "objectID": "claudemdfiles/SEO_SETUP_GUIDE.html#whats-been-configured",
    "href": "claudemdfiles/SEO_SETUP_GUIDE.html#whats-been-configured",
    "title": "Google Search Engine Optimization (SEO) Setup Guide",
    "section": "",
    "text": "Your Quarto website is now configured for better search engine indexing:\n\n\n\nQuarto automatically generates sitemap.xml at https://mcnakhaee.com/sitemap.xml\nThis helps Google discover all your pages\n\n\n\n\n\nCreated robots.txt file that tells search engines they can crawl your site\nPoints to your sitemap\n\n\n\n\n\nAdded description, keywords, and Open Graph tags\nEnabled Twitter Card support\nAdded structured metadata to homepage\n\n\n\n\n\nBlog RSS feed available at https://mcnakhaee.com/blog/index.xml"
  },
  {
    "objectID": "claudemdfiles/SEO_SETUP_GUIDE.html#next-steps-submit-your-site-to-google",
    "href": "claudemdfiles/SEO_SETUP_GUIDE.html#next-steps-submit-your-site-to-google",
    "title": "Google Search Engine Optimization (SEO) Setup Guide",
    "section": "",
    "text": "Go to Google Search Console\nClick “Start Now” and sign in with your Google account\nClick “Add Property”\nEnter your domain: mcnakhaee.com\n\n\n\n\nChoose one of these verification methods:\n\n\n\nGoogle will give you an HTML file to download (e.g., google1234567890abcdef.html)\nPlace this file in the root of your website directory\nRender your site: quarto render\nCommit and push to GitHub\nWait for Netlify to deploy\nClick “Verify” in Google Search Console\n\n\n\n\n\nGoogle will give you a meta tag like: &lt;meta name=\"google-site-verification\" content=\"abc123...\" /&gt;\nAdd this to your index.qmd frontmatter:\n---\ntitle: \"Muhammad Nakhaee\"\ngoogle-site-verification: \"abc123...\"\n---\nRender, commit, push, and verify\n\n\n\n\n\n\nOnce verified, in Google Search Console, go to “Sitemaps”\nEnter: sitemap.xml\nClick “Submit”\n\n\n\n\n\nGo to Google Analytics\nCreate a new property for your website\nGet your Measurement ID (format: G-XXXXXXXXXX)\nUpdate _quarto.yml with your real ID:\ngoogle-analytics: \"G-YOUR-ACTUAL-ID\"\nRender, commit, and push"
  },
  {
    "objectID": "claudemdfiles/SEO_SETUP_GUIDE.html#additional-seo-best-practices",
    "href": "claudemdfiles/SEO_SETUP_GUIDE.html#additional-seo-best-practices",
    "title": "Google Search Engine Optimization (SEO) Setup Guide",
    "section": "",
    "text": "Descriptive page titles\nMeta descriptions\nSemantic HTML structure\nMobile-responsive design\nFast loading (static site)\nHTTPS (via Netlify)\nSocial media meta tags\n\n\n\n\n\nAdd alt text to all images - Helps with accessibility and SEO\nInternal linking - Link between related posts and pages\nRegular content updates - Post consistently to your blog\nQuality content - Focus on valuable, original content\nShare on social media - Increases visibility and backlinks"
  },
  {
    "objectID": "claudemdfiles/SEO_SETUP_GUIDE.html#checking-indexing-status",
    "href": "claudemdfiles/SEO_SETUP_GUIDE.html#checking-indexing-status",
    "title": "Google Search Engine Optimization (SEO) Setup Guide",
    "section": "",
    "text": "After submitting to Google Search Console: - Wait 24-48 hours for Google to crawl your site - Check coverage report in Search Console - Use site search: site:mcnakhaee.com in Google to see indexed pages"
  },
  {
    "objectID": "claudemdfiles/SEO_SETUP_GUIDE.html#monitoring-performance",
    "href": "claudemdfiles/SEO_SETUP_GUIDE.html#monitoring-performance",
    "title": "Google Search Engine Optimization (SEO) Setup Guide",
    "section": "",
    "text": "Google Search Console provides: - Number of indexed pages - Search queries bringing traffic - Click-through rates - Mobile usability issues - Security problems"
  },
  {
    "objectID": "claudemdfiles/SEO_SETUP_GUIDE.html#quick-commands",
    "href": "claudemdfiles/SEO_SETUP_GUIDE.html#quick-commands",
    "title": "Google Search Engine Optimization (SEO) Setup Guide",
    "section": "",
    "text": "# Render your site locally\nquarto render\n\n# Add files and commit\ngit add .\ngit commit -m \"Update SEO configuration\"\n\n# Push to deploy\ngit push origin quarto"
  },
  {
    "objectID": "claudemdfiles/SEO_SETUP_GUIDE.html#resources",
    "href": "claudemdfiles/SEO_SETUP_GUIDE.html#resources",
    "title": "Google Search Engine Optimization (SEO) Setup Guide",
    "section": "",
    "text": "Google Search Console Help\nQuarto SEO Documentation\nNetlify SEO Guide\n\n\nNote: Google indexing can take several days to weeks. Be patient and keep creating quality content!"
  },
  {
    "objectID": "claudemdfiles/MIGRATION_SUMMARY.html",
    "href": "claudemdfiles/MIGRATION_SUMMARY.html",
    "title": "Projects Migration Summary",
    "section": "",
    "text": "I’ve successfully migrated your three projects from your Distill blog to the Quarto website. Here are the new project pages:\n\n\n\nLocation: projects/projects/tidytuesday/index.qmd\nDescription: Your weekly TidyTuesday submissions created using R and ggplot2\nCategories: R, data visualization, ggplot2\nGitHub: github.com/mcnakhaee/Tidy-Tuesday\n\n\n\n\n\nLocation: projects/projects/delgosha/index.qmd\nDescription: An R package providing ggplot2 themes for RTL languages (Persian)\nCategories: R, package development, RTL languages, Persian\nGitHub: github.com/mcnakhaee/delgosha\n\n\n\n\n\nLocation: projects/projects/palmerpenguins/index.qmd\nDescription: A Python package for loading the Palmer Penguins dataset\nCategories: Python, package development, data science, datasets\nGitHub: github.com/mcnakhaee/palmerpenguin\n\n\n\n\n\nYou need to copy three images from your old Distill blog to the new locations:\n\n\n\np:\\mcnakhaee\\mcnakhaee_com\\mcnakhaee_2024\\mcnakhaee.com\\imgs\\tidtuesday.png\np:\\mcnakhaee\\mcnakhaee_com\\mcnakhaee_2024\\mcnakhaee.com\\imgs\\delgosha.png\np:\\mcnakhaee\\mcnakhaee_com\\mcnakhaee_2024\\mcnakhaee.com\\imgs\\palmer.png\n\n\n\n\n\nCopy tidtuesday.png → projects\\projects\\tidytuesday\\tidytuesday.png\nCopy delgosha.png → projects\\projects\\delgosha\\delgosha.png\nCopy palmer.png → projects\\projects\\palmerpenguins\\palmer.png\n\n\n\n\n\nEach project page includes: - Comprehensive overview and description - Key features and technologies used - Installation and usage instructions (where applicable) - Links to GitHub repositories - What you learned from each project - Proper categorization for filtering\n\n\n\nThe main projects page (projects/index.qmd) now has: - Updated description focusing on open-source and data visualization work - Grid layout showing all 5 projects (2 original + 3 new) - Category filtering - Responsive design\n\n\n\nTo add more projects in the future: 1. Create a new folder in projects/projects/ 2. Add an index.qmd file with the project details 3. Add a project image 4. The project will automatically appear on the main projects page\n\n\n\n✅ All project pages created and rendering successfully ✅ Main projects page updated ✅ Site builds without errors ✅ Preview server running ⚠️ Project images need to be copied from old blog (see above)\nOnce you copy the images, the projects page will be complete!"
  },
  {
    "objectID": "claudemdfiles/MIGRATION_SUMMARY.html#projects-successfully-added",
    "href": "claudemdfiles/MIGRATION_SUMMARY.html#projects-successfully-added",
    "title": "Projects Migration Summary",
    "section": "",
    "text": "I’ve successfully migrated your three projects from your Distill blog to the Quarto website. Here are the new project pages:\n\n\n\nLocation: projects/projects/tidytuesday/index.qmd\nDescription: Your weekly TidyTuesday submissions created using R and ggplot2\nCategories: R, data visualization, ggplot2\nGitHub: github.com/mcnakhaee/Tidy-Tuesday\n\n\n\n\n\nLocation: projects/projects/delgosha/index.qmd\nDescription: An R package providing ggplot2 themes for RTL languages (Persian)\nCategories: R, package development, RTL languages, Persian\nGitHub: github.com/mcnakhaee/delgosha\n\n\n\n\n\nLocation: projects/projects/palmerpenguins/index.qmd\nDescription: A Python package for loading the Palmer Penguins dataset\nCategories: Python, package development, data science, datasets\nGitHub: github.com/mcnakhaee/palmerpenguin"
  },
  {
    "objectID": "claudemdfiles/MIGRATION_SUMMARY.html#next-step-add-project-images",
    "href": "claudemdfiles/MIGRATION_SUMMARY.html#next-step-add-project-images",
    "title": "Projects Migration Summary",
    "section": "",
    "text": "You need to copy three images from your old Distill blog to the new locations:\n\n\n\np:\\mcnakhaee\\mcnakhaee_com\\mcnakhaee_2024\\mcnakhaee.com\\imgs\\tidtuesday.png\np:\\mcnakhaee\\mcnakhaee_com\\mcnakhaee_2024\\mcnakhaee.com\\imgs\\delgosha.png\np:\\mcnakhaee\\mcnakhaee_com\\mcnakhaee_2024\\mcnakhaee.com\\imgs\\palmer.png\n\n\n\n\n\nCopy tidtuesday.png → projects\\projects\\tidytuesday\\tidytuesday.png\nCopy delgosha.png → projects\\projects\\delgosha\\delgosha.png\nCopy palmer.png → projects\\projects\\palmerpenguins\\palmer.png"
  },
  {
    "objectID": "claudemdfiles/MIGRATION_SUMMARY.html#what-was-created",
    "href": "claudemdfiles/MIGRATION_SUMMARY.html#what-was-created",
    "title": "Projects Migration Summary",
    "section": "",
    "text": "Each project page includes: - Comprehensive overview and description - Key features and technologies used - Installation and usage instructions (where applicable) - Links to GitHub repositories - What you learned from each project - Proper categorization for filtering"
  },
  {
    "objectID": "claudemdfiles/MIGRATION_SUMMARY.html#updated-main-projects-page",
    "href": "claudemdfiles/MIGRATION_SUMMARY.html#updated-main-projects-page",
    "title": "Projects Migration Summary",
    "section": "",
    "text": "The main projects page (projects/index.qmd) now has: - Updated description focusing on open-source and data visualization work - Grid layout showing all 5 projects (2 original + 3 new) - Category filtering - Responsive design"
  },
  {
    "objectID": "claudemdfiles/MIGRATION_SUMMARY.html#how-to-add-more-projects",
    "href": "claudemdfiles/MIGRATION_SUMMARY.html#how-to-add-more-projects",
    "title": "Projects Migration Summary",
    "section": "",
    "text": "To add more projects in the future: 1. Create a new folder in projects/projects/ 2. Add an index.qmd file with the project details 3. Add a project image 4. The project will automatically appear on the main projects page"
  },
  {
    "objectID": "claudemdfiles/MIGRATION_SUMMARY.html#current-status",
    "href": "claudemdfiles/MIGRATION_SUMMARY.html#current-status",
    "title": "Projects Migration Summary",
    "section": "",
    "text": "✅ All project pages created and rendering successfully ✅ Main projects page updated ✅ Site builds without errors ✅ Preview server running ⚠️ Project images need to be copied from old blog (see above)\nOnce you copy the images, the projects page will be complete!"
  },
  {
    "objectID": "claudemdfiles/PACKAGE_REQUIREMENTS.html",
    "href": "claudemdfiles/PACKAGE_REQUIREMENTS.html",
    "title": "Package Requirements for Migrated Blog Posts",
    "section": "",
    "text": "This document lists the R and Python packages referenced in the migrated blog posts.\n\n\nLocation: blog/posts/trump-speech-readability/index.qmd\n\n\n\ntidyverse - Data manipulation and visualization\nreticulate - R interface to Python\nggthemes - Additional themes for ggplot2\nus2020election - Custom package with US election speeches data (https://github.com/mcnakhaee/us2020election)\nggridges - Ridge plots for visualizations\nshowtext (optional) - Font management\nknitr - R Markdown support\n\n\n\n\n\nnumpy - Numerical computing\npandas - Data manipulation\ntextstat - Text readability metrics (https://github.com/shivam5992/textstat)\n\n\n\n\n\n\ninstall.packages(c(\"tidyverse\", \"reticulate\", \"ggthemes\", \"ggridges\", \"showtext\", \"knitr\"))\n\n# Install us2020election from GitHub\n# install.packages(\"devtools\")\n# devtools::install_github(\"mcnakhaee/us2020election\")\n\n\n\npip install numpy pandas textstat\n\n\n\n\n\n\nLocation: blog/posts/covid-19-netherlands/index.qmd\n\n\n\ntidyverse - Data manipulation and visualization\nCoronaWatchNL - Custom package for Netherlands COVID-19 data (https://github.com/mcnakhaee/CoronaWatchNL)\nsf - Spatial data handling\ngganimate - Animated visualizations\nsantoku - Data binning/chopping\nlubridate - Date/time handling (part of tidyverse)\nforeign - Reading foreign data formats\nknitr - R Markdown support\n\n\n\n\n\n\ninstall.packages(c(\"tidyverse\", \"sf\", \"gganimate\", \"santoku\", \"lubridate\", \"foreign\", \"knitr\"))\n\n# Install CoronaWatchNL from GitHub\n# install.packages(\"devtools\")\n# devtools::install_github(\"mcnakhaee/CoronaWatchNL\")\n\n\n\n\n\n\nBoth posts are currently configured with eval=FALSE for all code chunks. This means: - ✅ The code is displayed for educational purposes - ✅ The site renders without requiring all packages to be installed - ✅ No Python environment configuration is needed - ✅ Images and GIFs (if present in post directories) will still display\n\n\n\nIf you want to execute the code:\n\nInstall all required packages (see above)\nFor the Trump speech post, configure Python environment:\n\nUncomment the reticulate configuration in the setup chunk\nEnsure you have a conda environment or use reticulate::use_python()\n\nChange eval=FALSE to eval=TRUE in the chunks you want to run\nEnsure data files and dependencies are available\n\n\n\n\n\nThe us2020election and CoronaWatchNL packages are custom packages that need to be installed from GitHub\nFont configuration (Lobster, Poppins Light) may require system fonts to be installed\nAnimation GIFs should be placed in the respective post directories if you want them to display\nThe posts are currently optimized for display without execution, perfect for portfolio/documentation purposes"
  },
  {
    "objectID": "claudemdfiles/PACKAGE_REQUIREMENTS.html#trump-speech-readability-analysis-post",
    "href": "claudemdfiles/PACKAGE_REQUIREMENTS.html#trump-speech-readability-analysis-post",
    "title": "Package Requirements for Migrated Blog Posts",
    "section": "",
    "text": "Location: blog/posts/trump-speech-readability/index.qmd\n\n\n\ntidyverse - Data manipulation and visualization\nreticulate - R interface to Python\nggthemes - Additional themes for ggplot2\nus2020election - Custom package with US election speeches data (https://github.com/mcnakhaee/us2020election)\nggridges - Ridge plots for visualizations\nshowtext (optional) - Font management\nknitr - R Markdown support\n\n\n\n\n\nnumpy - Numerical computing\npandas - Data manipulation\ntextstat - Text readability metrics (https://github.com/shivam5992/textstat)\n\n\n\n\n\n\ninstall.packages(c(\"tidyverse\", \"reticulate\", \"ggthemes\", \"ggridges\", \"showtext\", \"knitr\"))\n\n# Install us2020election from GitHub\n# install.packages(\"devtools\")\n# devtools::install_github(\"mcnakhaee/us2020election\")\n\n\n\npip install numpy pandas textstat"
  },
  {
    "objectID": "claudemdfiles/PACKAGE_REQUIREMENTS.html#covid-19-netherlands-analysis-post",
    "href": "claudemdfiles/PACKAGE_REQUIREMENTS.html#covid-19-netherlands-analysis-post",
    "title": "Package Requirements for Migrated Blog Posts",
    "section": "",
    "text": "Location: blog/posts/covid-19-netherlands/index.qmd\n\n\n\ntidyverse - Data manipulation and visualization\nCoronaWatchNL - Custom package for Netherlands COVID-19 data (https://github.com/mcnakhaee/CoronaWatchNL)\nsf - Spatial data handling\ngganimate - Animated visualizations\nsantoku - Data binning/chopping\nlubridate - Date/time handling (part of tidyverse)\nforeign - Reading foreign data formats\nknitr - R Markdown support\n\n\n\n\n\n\ninstall.packages(c(\"tidyverse\", \"sf\", \"gganimate\", \"santoku\", \"lubridate\", \"foreign\", \"knitr\"))\n\n# Install CoronaWatchNL from GitHub\n# install.packages(\"devtools\")\n# devtools::install_github(\"mcnakhaee/CoronaWatchNL\")"
  },
  {
    "objectID": "claudemdfiles/PACKAGE_REQUIREMENTS.html#current-configuration",
    "href": "claudemdfiles/PACKAGE_REQUIREMENTS.html#current-configuration",
    "title": "Package Requirements for Migrated Blog Posts",
    "section": "",
    "text": "Both posts are currently configured with eval=FALSE for all code chunks. This means: - ✅ The code is displayed for educational purposes - ✅ The site renders without requiring all packages to be installed - ✅ No Python environment configuration is needed - ✅ Images and GIFs (if present in post directories) will still display"
  },
  {
    "objectID": "claudemdfiles/PACKAGE_REQUIREMENTS.html#to-enable-code-execution",
    "href": "claudemdfiles/PACKAGE_REQUIREMENTS.html#to-enable-code-execution",
    "title": "Package Requirements for Migrated Blog Posts",
    "section": "",
    "text": "If you want to execute the code:\n\nInstall all required packages (see above)\nFor the Trump speech post, configure Python environment:\n\nUncomment the reticulate configuration in the setup chunk\nEnsure you have a conda environment or use reticulate::use_python()\n\nChange eval=FALSE to eval=TRUE in the chunks you want to run\nEnsure data files and dependencies are available"
  },
  {
    "objectID": "claudemdfiles/PACKAGE_REQUIREMENTS.html#notes",
    "href": "claudemdfiles/PACKAGE_REQUIREMENTS.html#notes",
    "title": "Package Requirements for Migrated Blog Posts",
    "section": "",
    "text": "The us2020election and CoronaWatchNL packages are custom packages that need to be installed from GitHub\nFont configuration (Lobster, Poppins Light) may require system fonts to be installed\nAnimation GIFs should be placed in the respective post directories if you want them to display\nThe posts are currently optimized for display without execution, perfect for portfolio/documentation purposes"
  },
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Talks & Presentations",
    "section": "",
    "text": "I enjoy sharing knowledge and insights with the community through talks, workshops, and presentations. Here’s a collection of my speaking engagements.\n\n\n\n\n\nConference: Tech Summit 2025\nDate: October 15, 2025\nLocation: Virtual\nAn overview of modern web development practices, including React, TypeScript, and best practices for building scalable applications.\n\n\n\n\n\n\nNoteResources\n\n\n\n\nSlides (PDF)\nVideo Recording\nCode Examples"
  },
  {
    "objectID": "talks/index.html#section",
    "href": "talks/index.html#section",
    "title": "Talks & Presentations",
    "section": "",
    "text": "Conference: Tech Summit 2025\nDate: October 15, 2025\nLocation: Virtual\nAn overview of modern web development practices, including React, TypeScript, and best practices for building scalable applications.\n\n\n\n\n\n\nNoteResources\n\n\n\n\nSlides (PDF)\nVideo Recording\nCode Examples"
  },
  {
    "objectID": "projects/projects/mynextchart/index.html",
    "href": "projects/projects/mynextchart/index.html",
    "title": "My Next Chart",
    "section": "",
    "text": "My Next Chart is an innovative project that uses AI and embeddings to ‘understand’ and categorize data visualizations, making them semantically searchable. Instead of relying on keywords or tags, it analyzes the visual content and context of charts to help you find exactly the visualization you need."
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#overview",
    "href": "projects/projects/mynextchart/index.html#overview",
    "title": "My Next Chart",
    "section": "",
    "text": "My Next Chart is an innovative project that uses AI and embeddings to ‘understand’ and categorize data visualizations, making them semantically searchable. Instead of relying on keywords or tags, it analyzes the visual content and context of charts to help you find exactly the visualization you need."
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#the-story",
    "href": "projects/projects/mynextchart/index.html#the-story",
    "title": "My Next Chart",
    "section": "The Story",
    "text": "The Story\nI presented this project at PyData Amsterdam 2025, where I shared how it started and the technical challenges of building a semantic search engine for data visualizations."
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#key-features",
    "href": "projects/projects/mynextchart/index.html#key-features",
    "title": "My Next Chart",
    "section": "Key Features",
    "text": "Key Features\n\n\nSemantic Search\n\nMultimodal embeddings understand both images and text\nFind charts based on meaning, not just keywords\nAI-powered relevance ranking\n\n\n\nRich Data Sources\n\n#TidyTuesday contributions\nDatawrapper Dataviz Dispatch\nFlowingdata (work in progress)"
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#technology-stack",
    "href": "projects/projects/mynextchart/index.html#technology-stack",
    "title": "My Next Chart",
    "section": "Technology Stack",
    "text": "Technology Stack\n\nFrontend\n\nReact 19 - Modern UI framework\nTypeScript - Type-safe development\nTailwindCSS - Utility-first styling\nVite - Fast build tooling\n\n\n\nBackend\n\nFastAPI - High-performance Python web framework\nWeaviate - Vector database for similarity search\nPython - Core backend logic\n\n\n\nAI & Embeddings\n\nMistral - Language model embeddings\nCohere embed-v4.0 - Multimodal embeddings (text + images)\nMoonshot AI - LLM services\nQwen VL - Vision-language model"
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#how-it-works",
    "href": "projects/projects/mynextchart/index.html#how-it-works",
    "title": "My Next Chart",
    "section": "How It Works",
    "text": "How It Works\n\nData Collection: Scrapes visualizations from trusted data viz sources\nEmbedding Generation: Creates multimodal embeddings using Cohere’s embed-v4.0\nVector Storage: Stores embeddings in Weaviate for fast similarity search\nSemantic Search: Users search with natural language, AI finds relevant visualizations\nSmart Ranking: LLM services help rank and explain results"
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#data-sources",
    "href": "projects/projects/mynextchart/index.html#data-sources",
    "title": "My Next Chart",
    "section": "Data Sources",
    "text": "Data Sources\nThe project indexes visualizations from some of my favorite data visualization resources:\n\n#TidyTuesday: Weekly data visualization challenges from the R community\nDatawrapper Dataviz Dispatch: Professional data journalism visualizations\nFlowingdata: Data visualization tutorials and examples (coming soon)"
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#project-architecture",
    "href": "projects/projects/mynextchart/index.html#project-architecture",
    "title": "My Next Chart",
    "section": "Project Architecture",
    "text": "Project Architecture\n# Example: Semantic search with embeddings\nfrom weaviate import Client\n\ndef search_visualizations(query: str, limit: int = 10):\n    # Generate query embedding\n    query_embedding = embed_text(query)\n    \n    # Search vector database\n    results = client.query.get(\"Visualization\", [\n        \"title\", \"description\", \"image_url\", \"source\"\n    ]).with_near_vector({\n        \"vector\": query_embedding\n    }).with_limit(limit).do()\n    \n    return results"
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#challenges-solved",
    "href": "projects/projects/mynextchart/index.html#challenges-solved",
    "title": "My Next Chart",
    "section": "Challenges Solved",
    "text": "Challenges Solved\n\nMultimodal Understanding: Combining visual and textual features for accurate search\nScalability: Efficiently indexing and searching thousands of visualizations\nRelevance: Using AI to understand context and user intent\nPerformance: Fast vector similarity search with Weaviate"
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#project-links",
    "href": "projects/projects/mynextchart/index.html#project-links",
    "title": "My Next Chart",
    "section": "Project Links",
    "text": "Project Links\n\n\n\n\n\n\nTipTry It Out\n\n\n\n\nLive Demo: mynextchart.com\nGitHub Repository: github.com/mcnakhaee/mynextchart\nPyData Talk: Watch on YouTube"
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#what-i-learned",
    "href": "projects/projects/mynextchart/index.html#what-i-learned",
    "title": "My Next Chart",
    "section": "What I Learned",
    "text": "What I Learned\nBuilding My Next Chart taught me:\n\nMultimodal AI: Working with models that understand both images and text\nVector Databases: Implementing efficient similarity search at scale\nSemantic Search: Moving beyond keyword matching to meaning-based retrieval\nFull-Stack AI: Combining React frontend with Python AI backend\nLLM Integration: Using language models to enhance search results\nData Visualization Indexing: Programmatically analyzing and categorizing charts"
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#future-plans",
    "href": "projects/projects/mynextchart/index.html#future-plans",
    "title": "My Next Chart",
    "section": "Future Plans",
    "text": "Future Plans\n\nExpand to more data visualization sources (Flowingdata, Tableau Public)\nAdd chart type classification\nImplement chart creation suggestions based on search intent\nBuild a recommendation system for similar visualizations\nAdd user-generated collections and bookmarks"
  },
  {
    "objectID": "projects/projects/mynextchart/index.html#disclaimer",
    "href": "projects/projects/mynextchart/index.html#disclaimer",
    "title": "My Next Chart",
    "section": "Disclaimer",
    "text": "Disclaimer\nThis is an experimental project exploring the intersection of AI and data visualization. Results may vary, and the system is continuously learning and improving.\n\nStatus: Active Development"
  },
  {
    "objectID": "projects/projects/palmerpenguins/index.html",
    "href": "projects/projects/palmerpenguins/index.html",
    "title": "{palmerpenguins}",
    "section": "",
    "text": "{palmerpenguins} is a Python package that provides easy access to the Palmer Penguins dataset, making it simple to load this popular dataset for data science education, exploration, and visualization in Python. This is the Python equivalent of the popular R package of the same name."
  },
  {
    "objectID": "projects/projects/palmerpenguins/index.html#overview",
    "href": "projects/projects/palmerpenguins/index.html#overview",
    "title": "{palmerpenguins}",
    "section": "",
    "text": "{palmerpenguins} is a Python package that provides easy access to the Palmer Penguins dataset, making it simple to load this popular dataset for data science education, exploration, and visualization in Python. This is the Python equivalent of the popular R package of the same name."
  },
  {
    "objectID": "projects/projects/palmerpenguins/index.html#project-links",
    "href": "projects/projects/palmerpenguins/index.html#project-links",
    "title": "{palmerpenguins}",
    "section": "Project Links",
    "text": "Project Links\n\n\n\n\n\n\nTipAccess the Package\n\n\n\n\nGitHub Repository: github.com/mcnakhaee/palmerpenguin\nPyPI: Install via pip install palmerpenguins"
  },
  {
    "objectID": "projects/projects/palmerpenguins/index.html#about-palmer-penguins",
    "href": "projects/projects/palmerpenguins/index.html#about-palmer-penguins",
    "title": "{palmerpenguins}",
    "section": "About Palmer Penguins",
    "text": "About Palmer Penguins\nThe Palmer Penguins dataset is a modern alternative to the classic Iris dataset. It contains size measurements for three penguin species observed on three islands in the Palmer Archipelago, Antarctica.\nThe dataset includes: - 344 penguins across 3 species - 7 variables including species, island, bill dimensions, flipper length, body mass, and sex - Real data collected by Dr. Kristen Gorman at Palmer Station, Antarctica"
  },
  {
    "objectID": "projects/projects/palmerpenguins/index.html#why-this-package",
    "href": "projects/projects/palmerpenguins/index.html#why-this-package",
    "title": "{palmerpenguins}",
    "section": "Why This Package?",
    "text": "Why This Package?\nWhile the Palmer Penguins dataset is available in R, Python users needed an easy way to access it. This package:\n\nSimplifies Data Loading: One-line import of the dataset\nMultiple Formats: Returns pandas DataFrames or raw data\nConsistent API: Follows Python conventions and best practices\nWell-Documented: Clear examples and use cases\nLightweight: Minimal dependencies"
  },
  {
    "objectID": "projects/projects/palmerpenguins/index.html#installation",
    "href": "projects/projects/palmerpenguins/index.html#installation",
    "title": "{palmerpenguins}",
    "section": "Installation",
    "text": "Installation\npip install palmerpenguins"
  },
  {
    "objectID": "projects/projects/palmerpenguins/index.html#basic-usage",
    "href": "projects/projects/palmerpenguins/index.html#basic-usage",
    "title": "{palmerpenguins}",
    "section": "Basic Usage",
    "text": "Basic Usage\nfrom palmerpenguins import load_penguins\n\n# Load the penguins dataset\npenguins = load_penguins()\n\n# Start exploring\nprint(penguins.head())\nprint(penguins.describe())"
  },
  {
    "objectID": "projects/projects/palmerpenguins/index.html#use-cases",
    "href": "projects/projects/palmerpenguins/index.html#use-cases",
    "title": "{palmerpenguins}",
    "section": "Use Cases",
    "text": "Use Cases"
  },
  {
    "objectID": "projects/projects/palmerpenguins/index.html#example-analysis",
    "href": "projects/projects/palmerpenguins/index.html#example-analysis",
    "title": "{palmerpenguins}",
    "section": "Example Analysis",
    "text": "Example Analysis\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom palmerpenguins import load_penguins\n\n# Load data\npenguins = load_penguins()\n\n# Create visualization\nsns.scatterplot(\n    data=penguins,\n    x=\"bill_length_mm\",\n    y=\"bill_depth_mm\",\n    hue=\"species\"\n)\nplt.title(\"Palmer Penguins: Bill Dimensions\")\nplt.show()"
  },
  {
    "objectID": "projects/projects/palmerpenguins/index.html#credits",
    "href": "projects/projects/palmerpenguins/index.html#credits",
    "title": "{palmerpenguins}",
    "section": "Credits",
    "text": "Credits\nDataset originally published by: - Dr. Kristen Gorman: Palmer Station, Antarctica LTER - Dr. Allison Horst: Artwork and R package —\nOpen source project available on GitHub and PyPI"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Posts",
    "section": "",
    "text": "Welcome to my blog! Here you’ll find my thoughts, experiments and visualizations explaining various topics related to data science, AI, and data visualization.\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nMyNextChart: How I’m using AI for data visualization and it’s not what you think\n\n\n\ndata-science\n\npython\n\nvisualization\n\n\n\nMy Next Chart is my personal project to use AI and embeddings make charts semantically searchable\n\n\n\nMuhammad Chenariyan Nakhaee\n\n\nNov 15, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nCovid-19 Trends in the Netherlands\n\n\n\nR\n\ndata visualization\n\nCovid-19\n\n\n\nBased on data published by RIVM, in this post I looked at how Covid-19 cases spread throughout the Netherlands.\n\n\n\nMuhammad Chenariyan Nakhaee\n\n\nMay 22, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Easy Is It to Understand What Donald Trump Says?\n\n\n\npolitics\n\ndata analysis\n\nNLP\n\npython\n\nR\n\n\n\nThe computational complexity of the language that Trump uses in his speeches\n\n\n\nMuhammad Chenariyan Nakhaee\n\n\nNov 3, 2020\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/trump-speech-readability/index.html",
    "href": "blog/posts/trump-speech-readability/index.html",
    "title": "How Easy Is It to Understand What Donald Trump Says?",
    "section": "",
    "text": "Aside from their political differences, Donald Trump and Barack Obama have very contrasting personalities, traits, and characters. Obama is known to be a great communicator and an articulate speaker whose speeches are used in English classes to show how one should speak proper English. On the other hand, Trump is not the most eloquent English speaker or US president in history. Every now and then, you can find a clip on the web where Donald Trump is being mocked for the way he speaks or mispronounces words. This is so obvious that even non-native English speakers can notice how Trump’s speeches are very simple and inarticulate. Of course, this was not a bad thing for Trump at all. Actually, almost every political analyst that you see on the news talks about the fact that a vast majority of Trump’s fervent supporters are not college-educated Americans. We can attribute this to the fact that he knows how to speak to his audience and his base supporters using their language (although it is more likely that he cannot speak English better than this level).\nThis post will investigate how difficult it is to understand what each US politician talked about in the 2020 US Election cycle. I will use several readability metrics that can help us compute text comprehensibility. A wide range of these measures are implemented in the {textstat} Python package, and it is super easy to calculate them using this package.\nAside from their political differences, Donald Trump and Barack Obama have very contrasting personalities, traits, and characters. Obama is known to be a great communicator and an articulate speaker whose speeches are used in English classes to show how one should speak proper English. On the other hand, Trump is not the most eloquent English speaker or US president in history. Every now and then, you can find a clip on the web where Donald Trump is mocked for the way he speaks or mispronounces words. This is so obvious that even non-native English speakers can notice how Trump’s speeches are very simple and inarticulate. Of course, this was not a bad thing for Trump at all. Actually, almost every political analyst you see on the news talks about the fact that a vast majority of Trump’s fervent supporters are not college-educated Americans. We can attribute this to the fact that he knows how to speak to his audience and his base supporters using their language (although it is more likely that he cannot speak English better than this level).\nThis post will investigate how difficult it is to understand what each US politician talked about in the 2020 US Election cycle. I will use several readability metrics that can help us compute text comprehensibility. A wide range of these measures is implemented in the {textstat} Python package, and it is super easy to calculate them using this package.\nI compiled a list of US Election-related speeches from rev.com and turned them into an R package called {us2020election}. I use this package as my data source for my analysis. Like some of my other posts, I use Python to perform the analysis and R to visualize my results. Now let’s get started by importing the necessary packages.\nI compiled a list of US Election-related speeches from rev.com and turned them into an R package called {us2020election}. I use this package as my data source for my analysis. Like some of my other posts, I use Python to perform the analysis and R to visualize my results. Now, let’s get started by importing the necessary packages.\nCode\nlibrary(tidyverse)\nlibrary(reticulate)\nlibrary(ggthemes)\nlibrary(us2020election)\nlibrary(ggridges)\ntheme_set(theme_tufte())\ntheme_update(legend.position = 'none',\n          text = element_text(family = 'Lobster'),\n          plot.title = element_text(margin = margin(t= 10,b= 5),family = 'Lobster'),\n          plot.subtitle = element_text(margin = margin(b= 10),family = 'Lobster'),\n          panel.background = element_rect(fill = '#FDF6E3'),\n          plot.background = element_rect(fill = '#FDF6E3'))\nCode\nimport numpy as np\nimport pandas as pd \nimport textstat\nThere are several readability measures for English text included in {textstat}. Calculating these measures is very straightforward and easy. I will explain what each metric represents in more detail.\nCode\nus_election_speeches = r.us_election_speeches\nus_election_speeches['Flesch_Reading_Ease_formula'] = us_election_speeches['text'].apply(lambda x: textstat.flesch_reading_ease(x))\nus_election_speeches['gunning_fog'] = us_election_speeches['text'].apply(lambda x: textstat.gunning_fog(x))\nus_election_speeches['smog_index'] = us_election_speeches['text'].apply(lambda x: textstat.smog_index(x))\nus_election_speeches['automated_readability_index'] = us_election_speeches['text'].apply(lambda x: textstat.automated_readability_index(x))\nus_election_speeches['coleman_liau_index'] = us_election_speeches['text'].apply(lambda x: textstat.coleman_liau_index(x))\nus_election_speeches['linsear_write_formula'] = us_election_speeches['text'].apply(lambda x: textstat.linsear_write_formula(x))\nus_election_speeches['dale_chall_readability_score'] = us_election_speeches['text'].apply(lambda x: textstat.dale_chall_readability_score(x))\nus_election_speeches['text_standard'] = us_election_speeches['text'].apply(lambda x: textstat.text_standard(x))\nus_election_speeches['text_standard_float'] = us_election_speeches['text'].apply(lambda x: textstat.text_standard(x,float_output  = True))\nLet’s look at the resulting dataframe.\nCode\nus_election_speeches &lt;- py$us_election_speeches \nus_election_speeches %&gt;% \nglimpse()\nNow I am going to visualize the changes in the distribution of speech complexity for each politician. To make things easier, I will select a list of politicians that I’d like to analyze in this post.\nCode\nspeakers &lt;- c('Barack Obama','Pete Buttigieg','Mike Pence','Elizabeth Warren','Bernie Sanders','Donald Trump','Kamala Harris','Joe Biden','Mike Bloomberg')\ncustom_palette &lt;-c(\n    'Mike Bloomberg' = '#4E79A7',\n    'Amy Klobuchar' = '#4E79A7',\n    'Joe Biden' = '#4E79A7',\n    'Pete Buttigieg' = '#4E79A7',\n    'Elizabeth Warren' =  '#4E79A7',\n    'Barack Obama'  = '#4E79A7',\n    'Bernie Sanders' = '#4E79A7',\n    'Kamala Harris' = '#4E79A7',\n    'Donald Trump'  = '#E15759' ,\n     'Mike Pence' = '#E15759' \n  )\nAlso, I created a function to make ridge plots for each metric easier.\nCode\ncreate_plot &lt;- function(metric = Flesch_Reading_Ease_formula,subtitle = subtitle) {\n  metrics &lt;- rlang::enquo(metric)\n  us_election_speeches %&gt;%\n    separate_rows(speaker, sep = ',') %&gt;%\n    filter(speaker %in% speakers, type != 'Debate') %&gt;%\n    add_count(speaker) %&gt;%\n    ggplot() +\n    geom_density_ridges(aes(\n      x = !!metrics ,\n      y = speaker,\n      fill = speaker\n    )) +\n    labs(x = '', y = '',title = \"How Easy Is It to Comprehend Different US Politicians?\",subtitle = str_wrap(subtitle,width = 100)) +\n    scale_fill_manual(values = custom_palette) \n}\nNow, let’s look at several readability measures in more depth."
  },
  {
    "objectID": "blog/posts/trump-speech-readability/index.html#flesch-reading-ease-scores",
    "href": "blog/posts/trump-speech-readability/index.html#flesch-reading-ease-scores",
    "title": "How Easy Is It to Understand What Donald Trump Says?",
    "section": "Flesch Reading Ease Scores",
    "text": "Flesch Reading Ease Scores\nThe first readability score that I will look at is based on the Flesch Reading Ease formula. It computes the number of syllables to determine how easy a piece of text is. The maximum value of Flesch Reading Ease is 122, and there is no minimum value for it. Higher Flesch Reading Ease scores indicate that the text (speech) is easier to understand by the audience. In our case, it would show how sophisticated each politician is in terms of language use. You can find more about this metric on Wikipedia!\n\n\nCode\ncreate_plot(Flesch_Reading_Ease_formula ,\n            subtitle = 'The Flesch Reading Ease scores measure the complexity of a text document. Higher scores indicate a text is easier to comprehend.')\n\n\nWe can interpret the scores using the following table:\n\n\n\n\n\n\n\n\nScore\nSchool level\nNotes\n\n\n\n\n100.00–90.00\n5th grade\nVery easy to read. Easily understood by an average 11-year-old student.\n\n\n90.0–80.0\n6th grade\nEasy to read. Conversational English for consumers.\n\n\n80.0–70.0\n7th grade\nFairly easy to read.\n\n\n70.0–60.0\n8th & 9th grade\nPlain English. Easily understood by 13- to 15-year-old students.\n\n\n60.0–50.0\n10th to 12th grade\nFairly difficult to read.\n\n\n50.0–30.0\nCollege\nDifficult to read.\n\n\n30.0–10.0\nCollege graduate\nVery difficult to read. Best understood by university graduates.\n\n\n10.0–0.0\nProfessional\nExtremely difficult to read. Best understood by university graduates."
  },
  {
    "objectID": "blog/posts/trump-speech-readability/index.html#gunning-fog-index",
    "href": "blog/posts/trump-speech-readability/index.html#gunning-fog-index",
    "title": "How Easy Is It to Understand What Donald Trump Says?",
    "section": "Gunning Fog Index",
    "text": "Gunning Fog Index\nThe Gunning fog index is another metric to measure the complexity of a text document. It shows how many years of education one might need to understand a piece of text. Larger values of the Gunning fog index correspond to more difficult writings.\nThe Gunning fog index is another metric to measure the complexity of a text document. It shows how many years of education one might need to understand a piece of text. Larger values of the Gunning fog index correspond to more difficult writing.\n\n\nCode\ncreate_plot(gunning_fog,subtitle = 'The Gunning fog index measures the complexity of a text document. Larger values of the Gunning fog index correspond to more difficult writings.' )"
  },
  {
    "objectID": "blog/posts/trump-speech-readability/index.html#the-smog-index",
    "href": "blog/posts/trump-speech-readability/index.html#the-smog-index",
    "title": "How Easy Is It to Understand What Donald Trump Says?",
    "section": "The SMOG Index",
    "text": "The SMOG Index\nThe SMOG index computes the ratio of polysyllables (words with three or more syllables) in sentences to determine text complexity.\n\n\nCode\ncreate_plot(smog_index,subtitle = 'The SMOG index measures the complexity of a text document. Larger values of the SMOG index indicate more difficult writings.' )"
  },
  {
    "objectID": "blog/posts/trump-speech-readability/index.html#linsear-write-formula",
    "href": "blog/posts/trump-speech-readability/index.html#linsear-write-formula",
    "title": "How Easy Is It to Understand What Donald Trump Says?",
    "section": "Linsear Write Formula",
    "text": "Linsear Write Formula\nLike the previous metric, the Linsear Write Formula uses words with three or more syllables to compute text readability. It also relies on the sentence length to measure how difficult reading a text could be.\n\n\nCode\ncreate_plot(linsear_write_formula, subtitle = 'The Linsear Write Formula measures the complexity of a text document. Larger values indicate more difficult writings.')"
  },
  {
    "objectID": "blog/posts/trump-speech-readability/index.html#dale-chall-readability-score",
    "href": "blog/posts/trump-speech-readability/index.html#dale-chall-readability-score",
    "title": "How Easy Is It to Understand What Donald Trump Says?",
    "section": "Dale-Chall Readability Score",
    "text": "Dale-Chall Readability Score\nThis metric is different from the other metrics that we have talked about. It uses a dictionary of 3000 words that are easy to read and understand for a fourth-grade student. So, words that are not in this dictionary are considered to be complex. The higher the Dale-Chall Score is, the more difficult it is to read a text.\nThis metric is different from the other metrics that we have talked about. It uses a dictionary of 3,000 words that are easy to read and understand for a fourth-grade student. So, words that are not in this dictionary are considered to be complex. The higher the Dale-Chall Score is, the more difficult it is to read a text.\n\n\nCode\ncreate_plot(dale_chall_readability_score,subtitle = 'The Dale-Chall Readability Score measures the complexity of a text document. The higher the Dale-Chall Score is, the more difficult it is to read a text.')"
  },
  {
    "objectID": "blog/posts/trump-speech-readability/index.html#a-unified-readability-score",
    "href": "blog/posts/trump-speech-readability/index.html#a-unified-readability-score",
    "title": "How Easy Is It to Understand What Donald Trump Says?",
    "section": "A Unified Readability Score",
    "text": "A Unified Readability Score\nWe introduced several readability metrics, but each one of them might give us a slightly different result. There is a way in textstat to combine all these metrics and have a single readability metric.\n\n\nCode\nus_election_speeches %&gt;%\n  filter(speaker %in% speakers) %&gt;%\n  mutate(text_standard = str_replace(text_standard,' and ','-'),\n        text_standard = factor(\n    text_standard,\n    levels = c(\n      '4th-5th grade',\n      '5th-6th grade',\n      '6th-7th grade',\n      '7th-8th grade',\n      '8th-9th grade',\n      '9th-10th grade',\n      '10th-11th grade',\n      '11th-12th grade',\n      '12th-13th grade',\n      '14th-15th grade'\n    )\n  )) %&gt;%\n  count(speaker, text_standard) %&gt;%\n  mutate(n = n + 1) %&gt;%\n  ggplot()  +\n  geom_col(aes(x = text_standard , y =  n, fill = speaker)) +\n  labs(x = '', y = 'Number of Speeches', title = \"How Easy Is It to Understand Trump's Speeches?\",\n       subtitle = 'Based on several readability tests, the education level that one needs to comprehend the 2020 Election speeches by different US politicians is illustrated in this plot.' ) +\n  scale_fill_manual(values = custom_palette) +\n  scale_y_log10() +\n  facet_wrap(~ speaker, ncol = 1) +\n  theme(axis.text  = element_text(size = 13),\n        axis.title.y = element_text(size = 15,margin = margin(r = 10,l = 10)),\n        plot.title = element_text(size = 20,margin = margin(b = 10,t = 10)),\n        plot.subtitle = element_text(size = 14,margin = margin(b = 10)),\n        strip.text = element_text(size = 15))\n\n\nInterestingly, we can observe that Trump never gave a speech to an audience with difficulty more than the 7th or 8th grade. We can also convert this readability metric to numbers to visualize and compare it to other metrics.\nInterestingly, we can observe that Trump never gave a speech to an audience with a difficulty higher than the 7th or 8th grade. We can also convert this readability metric to numbers to visualize and compare it to other metrics.\n\n\nCode\ncreate_plot(text_standard_float,\n            subtitle = 'The complexity of a text document was measured based on several readability metrics where larger values indicate more difficult writings.')"
  },
  {
    "objectID": "blog/posts/trump-speech-readability/index.html#conclusion",
    "href": "blog/posts/trump-speech-readability/index.html#conclusion",
    "title": "How Easy Is It to Understand What Donald Trump Says?",
    "section": "Conclusion",
    "text": "Conclusion\nWe can consistently see that Trump’s speeches are less sophisticated and less complex than the speeches given by the rest of the politicians. We can attribute this to his lack of sophistication in terms of language, the fact that he knows how to speak to his audience, or both. Also, we can notice that Mike Pence and Barack Obama seem to use more advanced language in their speeches."
  },
  {
    "objectID": "blog/posts/covid-19-netherlands/index.html",
    "href": "blog/posts/covid-19-netherlands/index.html",
    "title": "Covid-19 Trends in the Netherlands",
    "section": "",
    "text": "Two weeks ago, I made a visualization that shows how Covid-19 cases spread in the Netherlands from the beginning of March and how grim the situation looked. However, someone pointed out the fact that the number of tests has increased significantly. It means that my plot may exaggerate the Covid-19 situation in the Netherlands. Unfortunately, I could not find testing data for each Dutch municipality. Instead, I decided to use hospitalization admissions and deceased cases to see if we can indeed see a massive spread in the second wave of Covid-19 cases in the Netherlands.\nCode\nlibrary(tidyverse)\nlibrary(CoronaWatchNL)\nlibrary(sf)\nlibrary(gganimate)\nlibrary(santoku)\nlibrary(lubridate)\nlibrary(foreign)\ntheme_set(theme_void())\ntheme_update(\n  #plot.background = element_rect(fill = '#FDF6E3',color = '#FDF6E3'),\n  text = element_text(family = 'Poppins Light'),\n  plot.subtitle = element_text(\n    family = 'Poppins Light',\n    size = 10,\n    margin = margin(b = 10)\n  ),\n  plot.title = element_text(\n    family = 'Poppins Light',\n    size = 12,\n    margin = margin(t = 10, b = 10)\n  )\n)\nI created an R package called CoronaWatchNL that allows you to access a wide range of Covid-19 datasets. I’ll use this package in this post to get Covid-19 cases, hospital admissions, and deaths for Dutch municipalities.\nCode\nmunicipalBoundaries &lt;- st_read(\n    \"https://geodata.nationaalgeoregister.nl/cbsgebiedsindelingen/wfs?request=GetFeature&service=WFS&version=2.0.0&typeName=cbs_gemeente_2020_gegeneraliseerd&outputFormat=json\"\n  )\n\ndaily_cases_per_municpality &lt;- get_daily_cases_per_municipality()\npopulatuon_per_region &lt;- get_population_per_region()\n\ndaily_cases_per_municpality &lt;- daily_cases_per_municpality %&gt;%\n  inner_join(populatuon_per_region, by = c('Municipality_name' = 'Regions')) %&gt;%\n  mutate(\n    Date_of_publication = as_date(Date_of_publication),\n    avg_daily_total_cases = 100000 * as.numeric(Total_reported) / as.numeric(`Bevolking op 1 januari (aantal)`),\n    avg_daily_hospital_admissions = 100000 * as.numeric(Hospital_admission) / as.numeric(`Bevolking op 1 januari (aantal)`),\n    avg_daily_deceased = 100000 * as.numeric(Deceased) / as.numeric(`Bevolking op 1 januari (aantal)`)\n  )\nI compute the weekly average number of Covid-19 cases, hospitalizations, and deaths per 100,000 inhabitants in each municipality in the Netherlands. The following piece of code shows how I did this using R.\nCode\nweekly_cases &lt;- daily_cases_per_municpality %&gt;%\n  mutate(week = round_date(Date_of_publication , unit = 'week'))\n\nweekly_cases_per_municpality &lt;- weekly_cases %&gt;%\n  group_by(Municipality_name, week) %&gt;%\n  summarise(\n    avg_weekly_total_cases = mean(avg_daily_total_cases),\n    avg_weekly_hospital_admissions = mean(avg_daily_hospital_admissions),\n    avg_weekly_deceased = mean(avg_daily_deceased)) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    d_avg_weekly_total_cases = chop(avg_weekly_total_cases, c(0, 0, 0.5, 1, 5, 12, 20, 35, 55, 80, 100)),\n    d_avg_hospital_admissions = chop(\n      avg_weekly_hospital_admissions,\n      c(0, 0, 0.5, 1, 2, 3, 5, 7, 9, 10, 15)),\n    d_avg_weekly_deceased = chop(avg_weekly_deceased, c(0, 0, 0.1, 0.5, 1, 1.5, 2, 2.5, 3, 5)))\n\ndata_weekly &lt;- municipalBoundaries %&gt;%\n  right_join(weekly_cases_per_municpality,\n             by = c(statnaam = \"Municipality_name\"))\nI will create an animation that shows how Covid-19 cases spread in the Netherlands and which municipalities were and are hit hardest by the pandemic.\nCode\nmake_animation &lt;- function(data, var_name, pal, title) {\n  var_name &lt;- rlang::enquo(var_name)\n  data %&gt;%\n    #filter(week &gt; '2020-10-01') %&gt;%\n    ggplot() +\n    geom_sf(aes(fill = !!var_name), color = 'gray95') +\n    scale_fill_manual(values  = pal) +\n    coord_sf(datum = NA) +\n    labs(\n      title = title,\n      subtitle = 'Date: {current_frame}',\n      fill = 'Counts per 100,000',\n      caption = 'Source: RIVM'\n    ) +\n    transition_manual(week, cumulative = T) +\n    ease_aes(\"sine\") +\n    enter_fade(alpha = 0.5) +\n    exit_fade(alpha = 0.5)\n}"
  },
  {
    "objectID": "blog/posts/covid-19-netherlands/index.html#covid-19-cases",
    "href": "blog/posts/covid-19-netherlands/index.html#covid-19-cases",
    "title": "Covid-19 Trends in the Netherlands",
    "section": "Covid-19 Cases",
    "text": "Covid-19 Cases\nThe first animation shows the number of infections in each municipality, from the start of the pandemic in February until recently. As you can see, the second wave, which began in late September, looks really terrifying. Note that there are some municipalities for which no data is available.\n\n\nCode\npal_cases &lt;- c(\n      'gray95',\n      '#fee440',\n      '#FFBA08',\n      '#FAA307',\n      '#F48C06',\n      '#E85D04',\n      '#DC2F02',\n      '#D00000',\n      '#9D0208',\n      '#6A040F',\n      '#370617',\n      '#03071e'\n    )\nmake_animation(data_weekly,d_avg_weekly_total_cases,pal_cases,'The Average Weekly Number of Covid-19 Cases\\nper 100,000 Inhabitants in the Netherlands')"
  },
  {
    "objectID": "blog/posts/covid-19-netherlands/index.html#hospital-admissions",
    "href": "blog/posts/covid-19-netherlands/index.html#hospital-admissions",
    "title": "Covid-19 Trends in the Netherlands",
    "section": "Hospital Admissions",
    "text": "Hospital Admissions\nIf we look at the number of hospital admissions, we see a different story. It seems that the number of hospitalizations was higher during the first wave of Covid-19 compared to the second wave, and mostly the southern parts of the Netherlands were hit harder than the rest of the Netherlands.\n\n\nCode\npal_patients &lt;- c(\n      'gray95',\n      '#caf0f8',\n      '#ade8f4',\n      '#90e0ef',\n      '#48cae4',\n      '#00b4d8',\n      '#0096c7',\n      '#0077b6',\n      '#023e8a',\n      '#03045e',\n      '#03071e'\n)\nmake_animation(data_weekly,d_avg_hospital_admissions,pal_patients,'The Average Weekly Number of Hospital Admissions\\nper 100,000 Inhabitants in the Netherlands')"
  },
  {
    "objectID": "blog/posts/covid-19-netherlands/index.html#deaths",
    "href": "blog/posts/covid-19-netherlands/index.html#deaths",
    "title": "Covid-19 Trends in the Netherlands",
    "section": "Deaths",
    "text": "Deaths\nThe trend for deceased patients looks similar to that of hospital admissions. The average number of deaths during the first wave of coronavirus was higher than the average number of deaths during the second wave.\n\n\nCode\npal_deceased &lt;- c(\n      'gray95',\n      '#fdc5f5',\n     '#e0aaff',\n      '#c77dff',\n      '#9d4edd',\n      '#7b2cbf',\n      '#5a189a',\n      '#3c096c',\n      '#240046',\n      '#10002b'\n)\nmake_animation(data_weekly,d_avg_weekly_deceased,pal_deceased,'The Average Weekly Number of Deceased Patients\\nper 100,000 Inhabitants in the Netherlands')"
  },
  {
    "objectID": "blog/posts/covid-19-netherlands/index.html#conclusion",
    "href": "blog/posts/covid-19-netherlands/index.html#conclusion",
    "title": "Covid-19 Trends in the Netherlands",
    "section": "Conclusion",
    "text": "Conclusion\nThese different animations show us two distinct trends. On the one hand, we can see the number of confirmed cases rose rapidly during the second wave to affect almost all regions. On the other hand, the number of hospitalizations and deaths during the second wave slightly decreased. This might suggest that the rise in the number of cases is mainly driven by an increase in the number of tests. Alternatively, the virus might have become less deadly and severe."
  },
  {
    "objectID": "blog/posts/mynextchart/index.html",
    "href": "blog/posts/mynextchart/index.html",
    "title": "MyNextChart: How I’m using AI for data visualization and it’s not what you think",
    "section": "",
    "text": "This is a short blog post to introduce my new project, MyNextChart which came from my frustration with keeping track of 1000s of data visualizations inspirations I saw on the internet and my eternal struggle to categorize them and make sense of them.\nI presented this project at PyData Amsterdam 2025 this year and you can find the recording here: MyNextChart: How I Use AI for Data Visualization and It’s not to make Chart Slop. So this blog post will be just a short summary of the talk without going into the details of the project. I’ll write more about the technical details of how I built this project in a future post."
  },
  {
    "objectID": "blog/posts/mynextchart/index.html#intro",
    "href": "blog/posts/mynextchart/index.html#intro",
    "title": "MyNextChart: How I’m using AI for data visualization and it’s not what you think",
    "section": "",
    "text": "This is a short blog post to introduce my new project, MyNextChart which came from my frustration with keeping track of 1000s of data visualizations inspirations I saw on the internet and my eternal struggle to categorize them and make sense of them.\nI presented this project at PyData Amsterdam 2025 this year and you can find the recording here: MyNextChart: How I Use AI for Data Visualization and It’s not to make Chart Slop. So this blog post will be just a short summary of the talk without going into the details of the project. I’ll write more about the technical details of how I built this project in a future post."
  },
  {
    "objectID": "blog/posts/mynextchart/index.html#why-i-started-this-project",
    "href": "blog/posts/mynextchart/index.html#why-i-started-this-project",
    "title": "MyNextChart: How I’m using AI for data visualization and it’s not what you think",
    "section": "Why I started this project",
    "text": "Why I started this project\nIf you’re reading posts there is a big chance you have more than a 100 open tabs in your browser that you want to read later but never get to it? Or you have 1000s of saved bookmarks on your Twitter, LinkedIn, and other social media accounts that you never get to looked at them.\nI suffer from the same problem but probably even worse. I have around a few thousands or more bookmarked tweets, a few hundred bookmarked LinkedIn posts, and I have a few hundred open tabs in my browsers on different computers that I wanted to read look at but never get to it. One time I even realized that I had open tabs from 3 years ago!\nA large part of my bookmarked posts and tweets consist of data visualizations articles and charts that I find interesting and want to take inspiration from them for my own data visualizations. To alleviate my problem I have been using a few different applications like Notion to save and organize my bookmarked charts (and articles).\nI have been using these saved charts for inspiration when I’m working on a new data visualization project or for challenges such as #TidyTuesday or #30daychartchallenge. And sometimes I also scroll through github repositories for contribution made by others in the #TidyTuesday and #30daychartchallenge to find certain ways of doing things that I can use in my own projects (for example, how create spiral line charts).\n\n\n\n\n\n\nHowever, I realized that it was not practical to save all the charts I find interesting in Notion. The incoming stream of new charts and articles is way more than what I can save in Notion.\n\n\nBesides that, the same problem still persisted! I almost never looked at the saved charts in my Notion database. And even when I did, it was hard to find what I was looking for among hundreds of saved charts. In the end, I realized that I was spending way more cataloging charts that actually looking at them or creaiing my own charts.\n\n\n\nAt the time, I was working on our RAG (retrieval-augmented generation) solutions at my job (and I still do) and RAG became a hammer for me and every problem became naturally a nail.\n\n\n\nMy RAGnar hammer\n\n\nSo I thought what if instead of scrolling through my bookmarked charts and articles and hoping to find something interesting or useful, I could search for the type of charts that I’m looking for in natural language.\nFor example, what if I search for “circular bar charts” or “lection maps for germany” and get a list of relevant charts that match my query instead of looking through my large Notion gallery and hoping to spot something.\n\nSo, this became the start of mynextchart.com project. In essence it uses AI and embeddings to ‘understand’ and making them semantically searchable. In my talk at PyData Amsterdam 2025 I explained how I built this project and the technical challenges of building a semantic search engine for data visualizations. You can watch the recorded talk on YouTube.\n\n\n\nHow the architecture works in a simple image"
  },
  {
    "objectID": "projects/projects/delgosha/index.html",
    "href": "projects/projects/delgosha/index.html",
    "title": "{delgosha}",
    "section": "",
    "text": "{delgosha} is an R package that aims to provide a collection of ggplot2 themes specifically designed for Right-to-Left (RTL) languages, with a primary focus on Persian (Farsi). This package makes it easier for R users to create beautiful, publication-ready visualizations in Persian and other RTL languages."
  },
  {
    "objectID": "projects/projects/delgosha/index.html#overview",
    "href": "projects/projects/delgosha/index.html#overview",
    "title": "{delgosha}",
    "section": "",
    "text": "{delgosha} is an R package that aims to provide a collection of ggplot2 themes specifically designed for Right-to-Left (RTL) languages, with a primary focus on Persian (Farsi). This package makes it easier for R users to create beautiful, publication-ready visualizations in Persian and other RTL languages."
  },
  {
    "objectID": "projects/projects/delgosha/index.html#the-challenge",
    "href": "projects/projects/delgosha/index.html#the-challenge",
    "title": "{delgosha}",
    "section": "The Challenge",
    "text": "The Challenge\nCreating data visualizations in RTL languages like Persian, Arabic, or Hebrew presents unique challenges:\n\nFont support and rendering\nText alignment and direction\nLabel positioning\nTheme compatibility with RTL text"
  },
  {
    "objectID": "projects/projects/delgosha/index.html#solution",
    "href": "projects/projects/delgosha/index.html#solution",
    "title": "{delgosha}",
    "section": "Solution",
    "text": "Solution\n{delgosha} provides:\n\nRTL-Compatible Themes for Persian\nFont Management\nHelper Functions\nDocumentation"
  },
  {
    "objectID": "projects/projects/delgosha/index.html#key-features",
    "href": "projects/projects/delgosha/index.html#key-features",
    "title": "{delgosha}",
    "section": "Key Features",
    "text": "Key Features\n\n\nFor Users - Ready-to-use themes - Simple API - Persian font integration - Example gallery"
  },
  {
    "objectID": "projects/projects/delgosha/index.html#technologies-used",
    "href": "projects/projects/delgosha/index.html#technologies-used",
    "title": "{delgosha}",
    "section": "Technologies Used",
    "text": "Technologies Used\n\nR: Package development\nggplot2: Visualization framework\nroxygen2: Documentation\ntestthat: Testing framework\nGitHub Actions: Continuous integration"
  },
  {
    "objectID": "projects/projects/delgosha/index.html#package-philosophy",
    "href": "projects/projects/delgosha/index.html#package-philosophy",
    "title": "{delgosha}",
    "section": "Package Philosophy",
    "text": "Package Philosophy\nThe name “delgosha” (دلگشا) means “heartwarming” or “delightful” in Persian, reflecting the package’s goal to make data visualization in Persian a delightful experience rather than a frustrating one."
  },
  {
    "objectID": "projects/projects/delgosha/index.html#installation",
    "href": "projects/projects/delgosha/index.html#installation",
    "title": "{delgosha}",
    "section": "Installation",
    "text": "Installation\n# Install from GitHub\n# install.packages(\"devtools\")\ndevtools::install_github(\"mcnakhaee/delgosha\")"
  },
  {
    "objectID": "projects/projects/delgosha/index.html#basic-usage",
    "href": "projects/projects/delgosha/index.html#basic-usage",
    "title": "{delgosha}",
    "section": "Basic Usage",
    "text": "Basic Usage\nlibrary(delgosha)\nlibrary(ggplot2)\n\n# Create a plot with Persian theme\nggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point() +\n  theme_delgosha()"
  },
  {
    "objectID": "projects/projects/delgosha/index.html#project-links",
    "href": "projects/projects/delgosha/index.html#project-links",
    "title": "{delgosha}",
    "section": "Project Links",
    "text": "Project Links\n\n\n\n\n\n\nTipAccess the Package\n\n\n\n\nGitHub Repository: github.com/mcnakhaee/delgosha\nDocumentation: Full documentation and examples available in the repository\n\n\n\nOpen source project available on GitHub"
  },
  {
    "objectID": "projects/projects/tidytuesday/index.html",
    "href": "projects/projects/tidytuesday/index.html",
    "title": "TidyTuesday",
    "section": "",
    "text": "TidyTuesday is a weekly data project aimed at the R ecosystem. Every week, a new dataset is posted, and participants create visualizations and share their work on social media. This repository contains my submissions for the weekly TidyTuesday Project, created using R and ggplot2."
  },
  {
    "objectID": "projects/projects/tidytuesday/index.html#overview",
    "href": "projects/projects/tidytuesday/index.html#overview",
    "title": "TidyTuesday",
    "section": "",
    "text": "TidyTuesday is a weekly data project aimed at the R ecosystem. Every week, a new dataset is posted, and participants create visualizations and share their work on social media. This repository contains my submissions for the weekly TidyTuesday Project, created using R and ggplot2."
  },
  {
    "objectID": "projects/projects/tidytuesday/index.html#about-tidytuesday",
    "href": "projects/projects/tidytuesday/index.html#about-tidytuesday",
    "title": "TidyTuesday",
    "section": "About TidyTuesday",
    "text": "About TidyTuesday\nThe TidyTuesday project is:\n\nA safe and supportive forum for individuals to practice their data wrangling and visualization skills\nA weekly social data project that focuses on understanding data\nAn opportunity to work with real-world datasets and create compelling visualizations"
  },
  {
    "objectID": "projects/projects/tidytuesday/index.html#key-features",
    "href": "projects/projects/tidytuesday/index.html#key-features",
    "title": "TidyTuesday",
    "section": "Key Features",
    "text": "Key Features\n\nWeekly Visualizations: Regular contributions exploring diverse datasets\nR & ggplot2: All visualizations created using R’s powerful ggplot2 package\nData Storytelling: Each visualization tells a unique story about the data\nReproducible Code: All code is available for learning and reproduction"
  },
  {
    "objectID": "projects/projects/tidytuesday/index.html#technologies-used",
    "href": "projects/projects/tidytuesday/index.html#technologies-used",
    "title": "TidyTuesday",
    "section": "Technologies Used",
    "text": "Technologies Used\n\n\nLanguages & Tools - R - ggplot2 - tidyverse - RStudio\n\n\nSkills Demonstrated - Data wrangling - Statistical visualization - Design principles - Data storytelling"
  },
  {
    "objectID": "projects/projects/tidytuesday/index.html#sample-visualizations",
    "href": "projects/projects/tidytuesday/index.html#sample-visualizations",
    "title": "TidyTuesday",
    "section": "Sample Visualizations",
    "text": "Sample Visualizations\nMy TidyTuesday submissions cover a wide range of topics and datasets, including:\n\nEconomic trends and indicators\nSocial and demographic data\nSports statistics\nEnvironmental data\nCultural and entertainment data\n\nEach visualization is crafted to: - Clearly communicate insights from the data - Follow best practices in data visualization - Use effective color schemes and typography - Be accessible and easy to understand"
  },
  {
    "objectID": "projects/projects/tidytuesday/index.html#project-links",
    "href": "projects/projects/tidytuesday/index.html#project-links",
    "title": "TidyTuesday",
    "section": "Project Links",
    "text": "Project Links\n\n\n\n\n\n\nTipView My Work\n\n\n\n\nGitHub Repository: github.com/mcnakhaee/Tidy-Tuesday\nExplore my weekly submissions and see how different datasets can be visualized"
  },
  {
    "objectID": "projects/projects/tidytuesday/index.html#what-i-learned",
    "href": "projects/projects/tidytuesday/index.html#what-i-learned",
    "title": "TidyTuesday",
    "section": "What I Learned",
    "text": "What I Learned\nParticipating in TidyTuesday has helped me: - Develop stronger data visualization skills - Learn to work with diverse datasets quickly - Understand design principles for effective communication - Build a portfolio of data visualization work - Engage with the R community\n\nOngoing project with weekly contributions"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Projects\nA collection of my open-source projects, packages, and data visualization work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Next Chart\n\n\n\nPython\n\nAI\n\ndata visualization\n\nsemantic search\n\nFastAPI\n\nReact\n\n\n\nAn AI-powered semantic search engine for data visualizations using embeddings and vector databases\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday\n\n\n\nR\n\ndata visualization\n\nggplot2\n\n\n\nMy submissions for the weekly TidyTuesday Project created using R and ggplot2\n\n\n\n\n\n\n\n\n\n\n\n\n{delgosha}\n\n\n\nR\n\npackage development\n\nRTL languages\n\nPersian\n\n\n\nAn R package providing a collection of ggplot2 themes for RTL languages (mostly Persian)\n\n\n\n\n\n\n\n\n\n\n\n\n{palmerpenguins}\n\n\n\nPython\n\npackage development\n\ndata science\n\ndatasets\n\n\n\nA Python package for easily loading the Palmer Penguins dataset into your Python environment\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT.html",
    "href": "claudemdfiles/DEPLOYMENT.html",
    "title": "Deployment Guide for Netlify",
    "section": "",
    "text": "Backup your old distill blog (optional but recommended):\ngit checkout -b backup-distill\ngit push origin backup-distill\nSwitch to main branch and update:\ngit checkout main\nAdd your new Quarto website files:\ngit add .\ngit commit -m \"Migrate from distill to Quarto\"\ngit push origin main\n\n\n\n\nGo to your Netlify site dashboard:\n\nSite settings → Build & deploy → Build settings\nUpdate the settings:\n\nBuild command: quarto render\nPublish directory: _site\n\nEnvironment variables → Add:\n\nKey: QUARTO_VERSION\nValue: 1.4.0 (or latest version)\n\n\n\n\n\n\nClick Deploys → Trigger deploy → Deploy site\nYour new Quarto site will build and deploy!\n\n\n\n\n\n\nIf you prefer to deploy manually without CI/CD:\n\nBuild your site locally:\nquarto render\nDeploy the _site folder:\n\nDrag and drop the _site folder to Netlify’s deploy page\nOr use Netlify CLI:\nnpm install -g netlify-cli\nnetlify deploy --prod --dir=_site\n\n\n\n\n\n\n\nnetlify.toml - Netlify configuration file\n.gitignore - Already excludes _site folder\n\n\n\n\n\n\nRemove old distill files: Delete these if they exist:\n\n_site.yml (replaced by _quarto.yml)\nOld R Markdown files (.Rmd)\ndistill-specific configuration\n\nCustom domain: If you have a custom domain, keep your DNS settings in Netlify\nRedirects: The netlify.toml includes a catch-all redirect for client-side routing\nBuild time: First build may take 2-3 minutes\n\n\n\n\n\n\n\nMake sure QUARTO_VERSION environment variable is set in Netlify.\n\n\n\nClear your browser cache or do a hard refresh (Ctrl+Shift+R).\n\n\n\nCheck that publish directory is set to _site (not _site/ or docs).\n\n\n\n\n\n\nQuarto Publishing Guide\nNetlify Documentation"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT.html#option-1-using-github-recommended",
    "href": "claudemdfiles/DEPLOYMENT.html#option-1-using-github-recommended",
    "title": "Deployment Guide for Netlify",
    "section": "",
    "text": "Backup your old distill blog (optional but recommended):\ngit checkout -b backup-distill\ngit push origin backup-distill\nSwitch to main branch and update:\ngit checkout main\nAdd your new Quarto website files:\ngit add .\ngit commit -m \"Migrate from distill to Quarto\"\ngit push origin main\n\n\n\n\nGo to your Netlify site dashboard:\n\nSite settings → Build & deploy → Build settings\nUpdate the settings:\n\nBuild command: quarto render\nPublish directory: _site\n\nEnvironment variables → Add:\n\nKey: QUARTO_VERSION\nValue: 1.4.0 (or latest version)\n\n\n\n\n\n\nClick Deploys → Trigger deploy → Deploy site\nYour new Quarto site will build and deploy!"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT.html#option-2-manual-deployment",
    "href": "claudemdfiles/DEPLOYMENT.html#option-2-manual-deployment",
    "title": "Deployment Guide for Netlify",
    "section": "",
    "text": "If you prefer to deploy manually without CI/CD:\n\nBuild your site locally:\nquarto render\nDeploy the _site folder:\n\nDrag and drop the _site folder to Netlify’s deploy page\nOr use Netlify CLI:\nnpm install -g netlify-cli\nnetlify deploy --prod --dir=_site"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT.html#files-included-for-netlify",
    "href": "claudemdfiles/DEPLOYMENT.html#files-included-for-netlify",
    "title": "Deployment Guide for Netlify",
    "section": "",
    "text": "netlify.toml - Netlify configuration file\n.gitignore - Already excludes _site folder"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT.html#important-notes",
    "href": "claudemdfiles/DEPLOYMENT.html#important-notes",
    "title": "Deployment Guide for Netlify",
    "section": "",
    "text": "Remove old distill files: Delete these if they exist:\n\n_site.yml (replaced by _quarto.yml)\nOld R Markdown files (.Rmd)\ndistill-specific configuration\n\nCustom domain: If you have a custom domain, keep your DNS settings in Netlify\nRedirects: The netlify.toml includes a catch-all redirect for client-side routing\nBuild time: First build may take 2-3 minutes"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT.html#troubleshooting",
    "href": "claudemdfiles/DEPLOYMENT.html#troubleshooting",
    "title": "Deployment Guide for Netlify",
    "section": "",
    "text": "Make sure QUARTO_VERSION environment variable is set in Netlify.\n\n\n\nClear your browser cache or do a hard refresh (Ctrl+Shift+R).\n\n\n\nCheck that publish directory is set to _site (not _site/ or docs)."
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT.html#resources",
    "href": "claudemdfiles/DEPLOYMENT.html#resources",
    "title": "Deployment Guide for Netlify",
    "section": "",
    "text": "Quarto Publishing Guide\nNetlify Documentation"
  },
  {
    "objectID": "claudemdfiles/IMAGES_README.html",
    "href": "claudemdfiles/IMAGES_README.html",
    "title": "Project Images",
    "section": "",
    "text": "This directory should contain the following images for the project cards:\n\n\n\ntidytuesday.png - TidyTuesday project thumbnail\n\nRecommended size: 400x300px or similar aspect ratio\nShould show a sample TidyTuesday visualization\n\ndelgosha.png - Delgosha R package thumbnail\n\nRecommended size: 400x300px or similar aspect ratio\nCould show Persian text visualization or package logo\n\npalmer.png - Palmer Penguins package thumbnail\n\nRecommended size: 400x300px or similar aspect ratio\nCould show penguin illustrations or sample visualization\n\n\n\n\n\n\nImages are referenced in the respective project index.qmd files\nIf images are missing, Quarto will still render but show placeholder or no image\nYou can copy these images from your old Distill blog’s imgs/ directory\nSupported formats: PNG, JPG, SVG\n\n\n\n\n\nTidyTuesday: projects/projects/tidytuesday/tidytuesday.png\nDelgosha: projects/projects/delgosha/delgosha.png\nPalmer Penguins: projects/projects/palmerpenguins/palmer.png"
  },
  {
    "objectID": "claudemdfiles/IMAGES_README.html#required-images",
    "href": "claudemdfiles/IMAGES_README.html#required-images",
    "title": "Project Images",
    "section": "",
    "text": "tidytuesday.png - TidyTuesday project thumbnail\n\nRecommended size: 400x300px or similar aspect ratio\nShould show a sample TidyTuesday visualization\n\ndelgosha.png - Delgosha R package thumbnail\n\nRecommended size: 400x300px or similar aspect ratio\nCould show Persian text visualization or package logo\n\npalmer.png - Palmer Penguins package thumbnail\n\nRecommended size: 400x300px or similar aspect ratio\nCould show penguin illustrations or sample visualization"
  },
  {
    "objectID": "claudemdfiles/IMAGES_README.html#notes",
    "href": "claudemdfiles/IMAGES_README.html#notes",
    "title": "Project Images",
    "section": "",
    "text": "Images are referenced in the respective project index.qmd files\nIf images are missing, Quarto will still render but show placeholder or no image\nYou can copy these images from your old Distill blog’s imgs/ directory\nSupported formats: PNG, JPG, SVG"
  },
  {
    "objectID": "claudemdfiles/IMAGES_README.html#image-locations",
    "href": "claudemdfiles/IMAGES_README.html#image-locations",
    "title": "Project Images",
    "section": "",
    "text": "TidyTuesday: projects/projects/tidytuesday/tidytuesday.png\nDelgosha: projects/projects/delgosha/delgosha.png\nPalmer Penguins: projects/projects/palmerpenguins/palmer.png"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT_WORKFLOW.html",
    "href": "claudemdfiles/DEPLOYMENT_WORKFLOW.html",
    "title": "Deployment Workflow - Pre-Rendered Site",
    "section": "",
    "text": "Your Quarto website is now configured to be rendered locally and then deployed to Netlify as a static site. This approach is simpler and avoids the need to install R on Netlify’s build servers.\n\n\n\n\nLocal Rendering: You render the site on your local machine (where R is installed)\nGit Tracking: The _site folder is tracked in Git (not ignored)\nNetlify Deployment: Netlify simply serves the pre-built files from the _site folder\n\n\n\n\n\n\n\nMake changes to your .qmd files, projects, or blog posts\nRender locally:\nquarto render\nCommit and push:\ngit add -A\ngit commit -m \"Update site content\"\ngit push origin quarto\nNetlify automatically deploys the updated _site folder\n\n\n\n\n\n\n\n[build]\n  command = \"\"  # No build command - site is pre-rendered\n  publish = \"_site\"\n\n\n\n# _site/ is commented out so it's tracked in Git\n/.quarto/\n**/*.quarto_ipynb\n\n\n\n\n✅ Simple: No complex build setup on Netlify\n✅ Fast: Netlify just serves files, no rendering needed\n✅ Reliable: Builds happen locally where you control the environment\n✅ R Support: Full R support since you render where R is installed\n✅ Preview: You can test the site locally before deploying\n\n\n\n\nAlways run quarto render before committing\nThe _site folder will be large (contains all HTML, CSS, JS, images)\nMake sure to push the _site folder to Git\nNetlify will deploy automatically when you push to the quarto branch\n\n\n\n\nIf Netlify deployment fails: 1. Check that _site folder exists and is pushed to Git 2. Verify netlify.toml has publish = \"_site\" 3. Check Netlify build logs for any errors\n\nYour site should now deploy successfully on Netlify! 🎉"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#overview",
    "href": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#overview",
    "title": "Deployment Workflow - Pre-Rendered Site",
    "section": "",
    "text": "Your Quarto website is now configured to be rendered locally and then deployed to Netlify as a static site. This approach is simpler and avoids the need to install R on Netlify’s build servers."
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#how-it-works",
    "href": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#how-it-works",
    "title": "Deployment Workflow - Pre-Rendered Site",
    "section": "",
    "text": "Local Rendering: You render the site on your local machine (where R is installed)\nGit Tracking: The _site folder is tracked in Git (not ignored)\nNetlify Deployment: Netlify simply serves the pre-built files from the _site folder"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#deployment-steps",
    "href": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#deployment-steps",
    "title": "Deployment Workflow - Pre-Rendered Site",
    "section": "",
    "text": "Make changes to your .qmd files, projects, or blog posts\nRender locally:\nquarto render\nCommit and push:\ngit add -A\ngit commit -m \"Update site content\"\ngit push origin quarto\nNetlify automatically deploys the updated _site folder"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#configuration-files",
    "href": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#configuration-files",
    "title": "Deployment Workflow - Pre-Rendered Site",
    "section": "",
    "text": "[build]\n  command = \"\"  # No build command - site is pre-rendered\n  publish = \"_site\"\n\n\n\n# _site/ is commented out so it's tracked in Git\n/.quarto/\n**/*.quarto_ipynb"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#benefits-of-this-approach",
    "href": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#benefits-of-this-approach",
    "title": "Deployment Workflow - Pre-Rendered Site",
    "section": "",
    "text": "✅ Simple: No complex build setup on Netlify\n✅ Fast: Netlify just serves files, no rendering needed\n✅ Reliable: Builds happen locally where you control the environment\n✅ R Support: Full R support since you render where R is installed\n✅ Preview: You can test the site locally before deploying"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#important-notes",
    "href": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#important-notes",
    "title": "Deployment Workflow - Pre-Rendered Site",
    "section": "",
    "text": "Always run quarto render before committing\nThe _site folder will be large (contains all HTML, CSS, JS, images)\nMake sure to push the _site folder to Git\nNetlify will deploy automatically when you push to the quarto branch"
  },
  {
    "objectID": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#troubleshooting",
    "href": "claudemdfiles/DEPLOYMENT_WORKFLOW.html#troubleshooting",
    "title": "Deployment Workflow - Pre-Rendered Site",
    "section": "",
    "text": "If Netlify deployment fails: 1. Check that _site folder exists and is pushed to Git 2. Verify netlify.toml has publish = \"_site\" 3. Check Netlify build logs for any errors\n\nYour site should now deploy successfully on Netlify! 🎉"
  },
  {
    "objectID": "claudemdfiles/PROFILE_IMAGE_SETUP.html",
    "href": "claudemdfiles/PROFILE_IMAGE_SETUP.html",
    "title": "Profile Image Setup",
    "section": "",
    "text": "Place your profile photo as profile.jpg in the root directory of your website.\n\n\n\nFilename: profile.jpg (or profile.png)\nLocation: Root directory (same level as index.qmd)\nRecommended size: 400x400 pixels minimum (square)\nFormat: JPG or PNG\nQuality: High resolution for best results\n\n\n\n\n\nChoose a professional photo where your face is clearly visible\nCrop it to a square (1:1 ratio)\nResize to at least 400x400 pixels\nSave as profile.jpg\nPlace in: p:\\mcnakhaee\\mcnakhaee_com\\mcnakhaee_2025\\mcnakhaee\\mcnakhaee.com\\profile.jpg\n\n\n\n\nIf no image is found, a placeholder with your initials “MCN” will display.\n\n\n\nUpdate line 46 in index.qmd:\n&lt;img src=\"your-image-name.jpg\" alt=\"Muhammad Chenariyan Nakhaee\" class=\"profile-image\"&gt;\nThe image will automatically be displayed in a circular frame with a floating animation effect."
  },
  {
    "objectID": "claudemdfiles/PROFILE_IMAGE_SETUP.html#required-image",
    "href": "claudemdfiles/PROFILE_IMAGE_SETUP.html#required-image",
    "title": "Profile Image Setup",
    "section": "",
    "text": "Place your profile photo as profile.jpg in the root directory of your website.\n\n\n\nFilename: profile.jpg (or profile.png)\nLocation: Root directory (same level as index.qmd)\nRecommended size: 400x400 pixels minimum (square)\nFormat: JPG or PNG\nQuality: High resolution for best results\n\n\n\n\n\nChoose a professional photo where your face is clearly visible\nCrop it to a square (1:1 ratio)\nResize to at least 400x400 pixels\nSave as profile.jpg\nPlace in: p:\\mcnakhaee\\mcnakhaee_com\\mcnakhaee_2025\\mcnakhaee\\mcnakhaee.com\\profile.jpg\n\n\n\n\nIf no image is found, a placeholder with your initials “MCN” will display.\n\n\n\nUpdate line 46 in index.qmd:\n&lt;img src=\"your-image-name.jpg\" alt=\"Muhammad Chenariyan Nakhaee\" class=\"profile-image\"&gt;\nThe image will automatically be displayed in a circular frame with a floating animation effect."
  },
  {
    "objectID": "workingposts/ai-data-visualization-not-chart-slop/index.html",
    "href": "workingposts/ai-data-visualization-not-chart-slop/index.html",
    "title": "MyNextChart: How I Use AI for Data Visualization and It’s not to make Chart Slop",
    "section": "",
    "text": "This is a short blog post to introduce my new project, MyNextChart which came from my frustration with keeping track of 1000s of data visualizations inspirations I saw on the internet and my eternal struggle to categorize them and make sense of them.\nI presented this project at PyData Amsterdam 2025 this year and you can find the recording here: MyNextChart: How I Use AI for Data Visualization and It’s not to make Chart Slop. So this blog post will be just a short summary of the talk without going into the details of the project.\nsss # How I started I started this project early this year when I participated in the #30daychartchallenge after a long break from creating data visualizations. I started my data visualization journey with the #TidyTuesday Like many others, I leanred and took inspiration from other people’s charts and the way of doing certian things (e.g. how to create a circular bar chart). But the biggest challenge I faced was to keep track of all the charts and graphs that I found on the internet and the websites I visited.\nI have been trying to keep track of all the data visualizations and charts using tools like Notiona and Pinterest and bookmarks to catalog the charts. But it took me a lot of time, it wasn’t efficient and it was subject to my mood of the day and worst I barely looked at the charts I saved. In the end I realized that I spend most of my time saving charts that actually creating them.\n\nHow I solved it\nAt the time (and still) I was working as an AI Engineer for a Dutch company and I was mostly working on our RAG (retrieval-augmented generation) pipeline to generate answers based on our ducumentations for our customers when they interact with our chatbot. So, naturally everything became a RAG problem for me. and I asked myself how can I use a RAG to retrieve the charts based on a natural language query instead of searching through my bookmarks and Pinterest boards or TidyTuesday github codes. and then the next question was is that how do you transform a chart into a semanitc vector for RAG.\n\n\nHow it was implemented\nI used the QWEN-VL-MAX model hosted on Alibaba Cloud to analyze the charts and transform them into a text. I used the Mistral Embedding model to convert the text into vectors I used Weaviate as my vector database to store the embeddings"
  },
  {
    "objectID": "workingposts/cineville-wrapped/index.html#about-this-project",
    "href": "workingposts/cineville-wrapped/index.html#about-this-project",
    "title": "Cineville Wrapped 2025",
    "section": "About This Project",
    "text": "About This Project\nThis interactive scrollytelling visualization summarizes my movie-watching journey in 2025 using my Cineville pass. It includes:\n\nHero Stats: Total screenings, cinemas visited, cities, and hours watched\nCinema Analysis: Top cinemas and an interactive map of all theaters visited\nMovie Taste: Genre breakdown (treemap), language distribution, and keyword cloud\nCinema Calendar: Monthly activity and a detailed heatmap\nRatings Analysis: Raincloud plot of rating distribution, top favorites, and least favorites\nGuilty Pleasures & Hot Takes: Where my ratings diverged from TMDB consensus\n\n\nTechnologies Used\n\nD3.js - Data-driven visualizations\nScrollama - Scroll-driven interactions\nMapLibre GL - Interactive cinema map\nTailwind CSS - Styling\n\nView Full Screen"
  },
  {
    "objectID": "gallery.html",
    "href": "gallery.html",
    "title": "Photography",
    "section": "",
    "text": "FILM PHOTOGRAPHY\n\n\n  ‹\n  ›\n  \n  \n    \n      \n        \n      \n      \n      NOVEMBER 2025\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      NOVEMBER 2025\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      NOVEMBER 2025\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      NOVEMBER 2025\n      \n        \n      \n    \n\n    \n    \n      \n        \n      \n      \n      NOVEMBER 2025\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      NOVEMBER 2025\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      NOVEMBER 2025\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      NOVEMBER 2025\n      \n        \n      \n    \n  \n\n\nURBAN LANDSCAPES\n\n\n  ‹\n  ›\n  \n  \n    \n      \n        \n      \n      \n      CITY LIFE\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      CITY LIFE\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      CITY LIFE\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      CITY LIFE\n      \n        \n      \n    \n\n    \n    \n      \n        \n      \n      \n      CITY LIFE\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      CITY LIFE\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      CITY LIFE\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      CITY LIFE\n      \n        \n      \n    \n  \n\n\nNATURE & GARDENS\n\n\n  ‹\n  ›\n  \n  \n    \n      \n        \n      \n      \n      GARDENS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      GARDENS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      GARDENS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      GARDENS\n      \n        \n      \n    \n\n    \n    \n      \n        \n      \n      \n      GARDENS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      GARDENS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      GARDENS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      GARDENS\n      \n        \n      \n    \n  \n\n\nPORTRAITS & MOMENTS\n\n\n  ‹\n  ›\n  \n  \n    \n      \n        \n      \n      \n      MOMENTS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      MOMENTS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      MOMENTS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      MOMENTS\n      \n        \n      \n    \n\n    \n    \n      \n        \n      \n      \n      MOMENTS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      MOMENTS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      MOMENTS\n      \n        \n      \n    \n\n    \n      \n        \n      \n      \n      MOMENTS\n      \n        \n      \n    \n  \n\n\n\n\n\n\n\n\n\n\nTipInstagram\n\n\n\nFor more photos and updates, follow me on Instagram: @mcnakhaee\n\n\n\nFilm photography collection. Click on any image to view full screen. Hover to pause the animation."
  }
]