---
title: "How Easy Is It to Understand What Donald Trump Says?"
description: "The computational complexity of the language that Trump uses in his speeches"
author: "Muhammad Chenariyan Nakhaee"
date: "2020-11-03"
categories: [politics, data analysis, NLP, python, R]
image: featured.JPG
format:
  html:
    code-fold: true
    code-tools: true
    toc: true
---

```{r include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	eval = FALSE
)
# Uncomment and configure if you have reticulate set up
# reticulate::use_condaenv('r-reticulate')
# library(showtext)
# font_add_google("Overpass", "Overpass")
# windowsFonts('Lobster' = 'Lobster')
```

Aside from their political differences, Donald Trump and Barack Obama have very contrasting personalities, traits, and characters. Obama is known to be a great communicator and an articulate speaker whose speeches are used in English classes to show how one should speak proper English. On the other hand, Trump is not the most eloquent English speaker or US president in history. Every now and then, you can find a clip on the web where Donald Trump is being mocked for the way he speaks or mispronounces words. This is so obvious that even non-native English speakers can notice how Trump's speeches are very simple and inarticulate. Of course, this was not a bad thing for Trump at all. Actually, almost every political analyst that you see on the news talks about the fact that a vast majority of Trump's fervent supporters are not college-educated Americans. We can attribute this to the fact that he knows how to speak to his audience and his base supporters using their language (although it is more likely that he cannot speak English better than this level).

This post will investigate how difficult it is to understand what each US politician talked about in the 2020 US Election cycle. I will use several readability metrics that can help us compute text comprehensibility. A wide range of these measures are implemented in the [{`textstat`}](https://github.com/shivam5992/textstat) Python package, and it is super easy to calculate them using this package.

Aside from their political differences, Donald Trump and Barack Obama have very contrasting personalities, traits, and characters. Obama is known to be a great communicator and an articulate speaker whose speeches are used in English classes to show how one should speak proper English. On the other hand, Trump is not the most eloquent English speaker or US president in history. Every now and then, you can find a clip on the web where Donald Trump is mocked for the way he speaks or mispronounces words. This is so obvious that even non-native English speakers can notice how Trump's speeches are very simple and inarticulate. Of course, this was not a bad thing for Trump at all. Actually, almost every political analyst you see on the news talks about the fact that a vast majority of Trump's fervent supporters are not college-educated Americans. We can attribute this to the fact that he knows how to speak to his audience and his base supporters using their language (although it is more likely that he cannot speak English better than this level).

This post will investigate how difficult it is to understand what each US politician talked about in the 2020 US Election cycle. I will use several readability metrics that can help us compute text comprehensibility. A wide range of these measures is implemented in the [{`textstat`}](https://github.com/shivam5992/textstat) Python package, and it is super easy to calculate them using this package.

I compiled a list of US Election-related speeches from rev.com and turned them into an R package called [`{us2020election}`](https://github.com/mcnakhaee/us2020election). I use this package as my data source for my analysis. Like some of my other posts, I use Python to perform the analysis and R to visualize my results. Now let's get started by importing the necessary packages.

::: {.callout-note}
This post uses R packages that need to be installed: `tidyverse`, `reticulate`, `ggthemes`, `us2020election`, `ggridges`. The code is shown for educational purposes but not executed in this rendered version.
:::

I compiled a list of US Election-related speeches from rev.com and turned them into an R package called [`{us2020election}`](https://github.com/mcnakhaee/us2020election). I use this package as my data source for my analysis. Like some of my other posts, I use Python to perform the analysis and R to visualize my results. Now, let's get started by importing the necessary packages.

```{r eval=FALSE}
library(tidyverse)
library(reticulate)
library(ggthemes)
library(us2020election)
library(ggridges)
theme_set(theme_tufte())
theme_update(legend.position = 'none',
          text = element_text(family = 'Lobster'),
          plot.title = element_text(margin = margin(t= 10,b= 5),family = 'Lobster'),
          plot.subtitle = element_text(margin = margin(b= 10),family = 'Lobster'),
          panel.background = element_rect(fill = '#FDF6E3'),
          plot.background = element_rect(fill = '#FDF6E3'))
```

```{python eval=FALSE}
import numpy as np
import pandas as pd 
import textstat
```

There are several readability measures for English text included in {`textstat`}. Calculating these measures is very straightforward and easy. I will explain what each metric represents in more detail.

```{python eval=FALSE}
us_election_speeches = r.us_election_speeches
us_election_speeches['Flesch_Reading_Ease_formula'] = us_election_speeches['text'].apply(lambda x: textstat.flesch_reading_ease(x))
us_election_speeches['gunning_fog'] = us_election_speeches['text'].apply(lambda x: textstat.gunning_fog(x))
us_election_speeches['smog_index'] = us_election_speeches['text'].apply(lambda x: textstat.smog_index(x))
us_election_speeches['automated_readability_index'] = us_election_speeches['text'].apply(lambda x: textstat.automated_readability_index(x))
us_election_speeches['coleman_liau_index'] = us_election_speeches['text'].apply(lambda x: textstat.coleman_liau_index(x))
us_election_speeches['linsear_write_formula'] = us_election_speeches['text'].apply(lambda x: textstat.linsear_write_formula(x))
us_election_speeches['dale_chall_readability_score'] = us_election_speeches['text'].apply(lambda x: textstat.dale_chall_readability_score(x))
us_election_speeches['text_standard'] = us_election_speeches['text'].apply(lambda x: textstat.text_standard(x))
us_election_speeches['text_standard_float'] = us_election_speeches['text'].apply(lambda x: textstat.text_standard(x,float_output  = True))
```

Let's look at the resulting dataframe.

```{r eval=FALSE}
us_election_speeches <- py$us_election_speeches 
us_election_speeches %>% 
glimpse()
```

Now I am going to visualize the changes in the distribution of speech complexity for each politician. To make things easier, I will select a list of politicians that I'd like to analyze in this post.

```{r eval=FALSE}
speakers <- c('Barack Obama','Pete Buttigieg','Mike Pence','Elizabeth Warren','Bernie Sanders','Donald Trump','Kamala Harris','Joe Biden','Mike Bloomberg')
custom_palette <-c(
    'Mike Bloomberg' = '#4E79A7',
    'Amy Klobuchar' = '#4E79A7',
    'Joe Biden' = '#4E79A7',
    'Pete Buttigieg' = '#4E79A7',
    'Elizabeth Warren' =  '#4E79A7',
    'Barack Obama'  = '#4E79A7',
    'Bernie Sanders' = '#4E79A7',
    'Kamala Harris' = '#4E79A7',
    'Donald Trump'  = '#E15759' ,
     'Mike Pence' = '#E15759' 
  )
```

Also, I created a function to make ridge plots for each metric easier.

```{r eval=FALSE}
create_plot <- function(metric = Flesch_Reading_Ease_formula,subtitle = subtitle) {
  metrics <- rlang::enquo(metric)
  us_election_speeches %>%
    separate_rows(speaker, sep = ',') %>%
    filter(speaker %in% speakers, type != 'Debate') %>%
    add_count(speaker) %>%
    ggplot() +
    geom_density_ridges(aes(
      x = !!metrics ,
      y = speaker,
      fill = speaker
    )) +
    labs(x = '', y = '',title = "How Easy Is It to Comprehend Different US Politicians?",subtitle = str_wrap(subtitle,width = 100)) +
    scale_fill_manual(values = custom_palette) 
}
```

Now, let's look at several readability measures in more depth.

## Flesch Reading Ease Scores

The first readability score that I will look at is based on the Flesch Reading Ease formula. It computes the number of syllables to determine how easy a piece of text is. The maximum value of Flesch Reading Ease is 122, and there is no minimum value for it. Higher Flesch Reading Ease scores indicate that the text (speech) is easier to understand by the audience. In our case, it would show how sophisticated each politician is in terms of language use. You can find more about this metric on [Wikipedia](https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests)!

```{r fig.height=6,fig.width=10,eval=FALSE}
create_plot(Flesch_Reading_Ease_formula ,
            subtitle = 'The Flesch Reading Ease scores measure the complexity of a text document. Higher scores indicate a text is easier to comprehend.')
```

We can interpret the scores using the following table:

| Score        | School level       | Notes                                                        |
| ------------ | ------------------ | ------------------------------------------------------------ |
| 100.00–90.00 | 5th grade          | Very easy to read. Easily understood by an average 11-year-old student. |
| 90.0–80.0    | 6th grade          | Easy to read. Conversational English for consumers.          |
| 80.0–70.0    | 7th grade          | Fairly easy to read.                                         |
| 70.0–60.0    | 8th & 9th grade    | Plain English. Easily understood by 13- to 15-year-old students. |
| 60.0–50.0    | 10th to 12th grade | Fairly difficult to read.                                    |
| 50.0–30.0    | College            | Difficult to read.                                           |
| 30.0–10.0    | College graduate   | Very difficult to read. Best understood by university graduates. |
| 10.0–0.0     | Professional       | Extremely difficult to read. Best understood by university graduates. |

## Gunning Fog Index

[The Gunning fog index](https://en.wikipedia.org/wiki/Gunning_fog_index) is another metric to measure the complexity of a text document. It shows how many years of education one might need to understand a piece of text. Larger values of the Gunning fog index correspond to more difficult writings.

[The Gunning fog index](https://en.wikipedia.org/wiki/Gunning_fog_index) is another metric to measure the complexity of a text document. It shows how many years of education one might need to understand a piece of text. Larger values of the Gunning fog index correspond to more difficult writing.

```{r fig.height=6,fig.width=10,eval=FALSE}
create_plot(gunning_fog,subtitle = 'The Gunning fog index measures the complexity of a text document. Larger values of the Gunning fog index correspond to more difficult writings.' )
```

## The SMOG Index

[The SMOG index](https://en.wikipedia.org/wiki/SMOG) computes the ratio of polysyllables (words with three or more syllables) in sentences to determine text complexity.

```{r fig.height=6,fig.width=10,eval=FALSE}
create_plot(smog_index,subtitle = 'The SMOG index measures the complexity of a text document. Larger values of the SMOG index indicate more difficult writings.' )
```

## Linsear Write Formula

Like the previous metric, [the Linsear Write Formula](https://en.wikipedia.org/wiki/Linsear_Write) uses words with three or more syllables to compute text readability. It also relies on the sentence length to measure how difficult reading a text could be.

```{r fig.height=6,fig.width=10,eval=FALSE}
create_plot(linsear_write_formula, subtitle = 'The Linsear Write Formula measures the complexity of a text document. Larger values indicate more difficult writings.')
```

## Dale-Chall Readability Score

This metric is different from the other metrics that we have talked about. It uses a dictionary of 3000 words that are easy to read and understand for a fourth-grade student. So, words that are not in this dictionary are considered to be complex. The higher the Dale-Chall Score is, the more difficult it is to read a text.

This metric is different from the other metrics that we have talked about. It uses a dictionary of 3,000 words that are easy to read and understand for a fourth-grade student. So, words that are not in this dictionary are considered to be complex. The higher the Dale-Chall Score is, the more difficult it is to read a text.

```{r fig.height=6,fig.width=10,eval=FALSE}
create_plot(dale_chall_readability_score,subtitle = 'The Dale-Chall Readability Score measures the complexity of a text document. The higher the Dale-Chall Score is, the more difficult it is to read a text.')
```

## A Unified Readability Score

We introduced several readability metrics, but each one of them might give us a slightly different result. There is a way in `textstat` to combine all these metrics and have a single readability metric.

```{r fig.height = 14, fig.width=15,eval=FALSE}
us_election_speeches %>%
  filter(speaker %in% speakers) %>%
  mutate(text_standard = str_replace(text_standard,' and ','-'),
        text_standard = factor(
    text_standard,
    levels = c(
      '4th-5th grade',
      '5th-6th grade',
      '6th-7th grade',
      '7th-8th grade',
      '8th-9th grade',
      '9th-10th grade',
      '10th-11th grade',
      '11th-12th grade',
      '12th-13th grade',
      '14th-15th grade'
    )
  )) %>%
  count(speaker, text_standard) %>%
  mutate(n = n + 1) %>%
  ggplot()  +
  geom_col(aes(x = text_standard , y =  n, fill = speaker)) +
  labs(x = '', y = 'Number of Speeches', title = "How Easy Is It to Understand Trump's Speeches?",
       subtitle = 'Based on several readability tests, the education level that one needs to comprehend the 2020 Election speeches by different US politicians is illustrated in this plot.' ) +
  scale_fill_manual(values = custom_palette) +
  scale_y_log10() +
  facet_wrap(~ speaker, ncol = 1) +
  theme(axis.text  = element_text(size = 13),
        axis.title.y = element_text(size = 15,margin = margin(r = 10,l = 10)),
        plot.title = element_text(size = 20,margin = margin(b = 10,t = 10)),
        plot.subtitle = element_text(size = 14,margin = margin(b = 10)),
        strip.text = element_text(size = 15))
```

Interestingly, we can observe that Trump never gave a speech to an audience with difficulty more than the 7th or 8th grade. We can also convert this readability metric to numbers to visualize and compare it to other metrics.

Interestingly, we can observe that Trump never gave a speech to an audience with a difficulty higher than the 7th or 8th grade. We can also convert this readability metric to numbers to visualize and compare it to other metrics.

```{r fig.height=6,fig.width=10,eval=FALSE}
create_plot(text_standard_float,
            subtitle = 'The complexity of a text document was measured based on several readability metrics where larger values indicate more difficult writings.')
```

## Conclusion

We can consistently see that Trump's speeches are less sophisticated and less complex than the speeches given by the rest of the politicians. We can attribute this to his lack of sophistication in terms of language, the fact that he knows how to speak to his audience, or both. Also, we can notice that Mike Pence and Barack Obama seem to use more advanced language in their speeches.
